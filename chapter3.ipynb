{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## shape error between label and out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataset = tf.data.TextLineDataset('./up_down_dataset.csv')\\\n",
    "    .batch(20)\\\n",
    "    .make_one_shot_iterator()\\\n",
    "    .get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = tf.decode_csv(dataset, record_defaults=[[0]]*11)\n",
    "feature = tf.stack(lines[:-1], axis=1)\n",
    "label = lines[-1]  # label, out shape error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer1 = tf.layers.dense(feature, units=10, activation=tf.nn.relu) # units = the number of node\n",
    "layer2 = tf.layers.dense(layer1, units=10, activation=tf.nn.relu)\n",
    "layer3 = tf.layers.dense(layer2, units=10, activation=tf.nn.relu)\n",
    "layer4 = tf.layers.dense(layer3, units=10, activation=tf.nn.relu)\n",
    "out = tf.layers.dense(layer4, units=1)  # label = 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label's shape (?,)\n",
      "out's shape (?, 1)\n"
     ]
    }
   ],
   "source": [
    "print(\"label's shape {}\".format(label.shape))\n",
    "print(\"out's shape {}\".format(out.shape))\n",
    "\n",
    "# label == [1,2,3,4,5,6]\n",
    "# out == [[1],[2],[3],[4],[5],[6]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## type error, int or float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = tf.decode_csv(dataset, record_defaults=[[0]]*11)\n",
    "feature = tf.stack(lines[:-1], axis=1)\n",
    "label = tf.expand_dims(lines[-1], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer1 = tf.layers.dense(feature, units=10, activation=tf.nn.relu) # units = the number of node\n",
    "layer2 = tf.layers.dense(layer1, units=10, activation=tf.nn.relu)\n",
    "layer3 = tf.layers.dense(layer2, units=10, activation=tf.nn.relu)\n",
    "layer4 = tf.layers.dense(layer3, units=10, activation=tf.nn.relu)\n",
    "out = tf.layers.dense(layer4, units=1)  # label = 0 or 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## uninitialize error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = tf.decode_csv(dataset, record_defaults=[[0]]*11)\n",
    "feature = tf.stack(lines[:-1], axis=1)\n",
    "label = tf.expand_dims(lines[-1], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature = tf.cast(feature, tf.float32)\n",
    "label = tf.cast(label, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer1 = tf.layers.dense(feature, units=10, activation=tf.nn.relu) # units = the number of node\n",
    "layer2 = tf.layers.dense(layer1, units=10, activation=tf.nn.relu)\n",
    "layer3 = tf.layers.dense(layer2, units=10, activation=tf.nn.relu)\n",
    "layer4 = tf.layers.dense(layer3, units=10, activation=tf.nn.relu)\n",
    "out = tf.layers.dense(layer4, units=1)  # label = 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "loss = tf.losses.sigmoid_cross_entropy(label, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_op = tf.train.GradientDescentOptimizer(1e-2).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value dense_34/bias\n\t [[{{node dense_34/bias/read}} = Identity[T=DT_FLOAT, _class=[\"loc:@GradientDescent/update_dense_34/bias/ApplyGradientDescent\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dense_34/bias)]]\n\nCaused by op 'dense_34/bias/read', defined at:\n  File \"/home/fwani/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/fwani/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-32-4f9e0b068a7b>\", line 5, in <module>\n    out = tf.layers.dense(layer4, units=1)  # label = 0 or 1\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/core.py\", line 184, in dense\n    return layer.apply(inputs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 828, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 364, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 759, in __call__\n    self.build(input_shapes)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py\", line 930, in build\n    trainable=True)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 278, in add_weight\n    getter=vs.get_variable)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 586, in add_weight\n    aggregation=aggregation)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py\", line 591, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1484, in get_variable\n    aggregation=aggregation)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1234, in get_variable\n    aggregation=aggregation)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 538, in get_variable\n    aggregation=aggregation)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 492, in _true_getter\n    aggregation=aggregation)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 920, in _get_single_variable\n    aggregation=aggregation)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 145, in __call__\n    return cls._variable_call(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 141, in _variable_call\n    aggregation=aggregation)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 120, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2441, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 147, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1104, in __init__\n    constraint=constraint)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1266, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 81, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3354, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value dense_34/bias\n\t [[{{node dense_34/bias/read}} = Identity[T=DT_FLOAT, _class=[\"loc:@GradientDescent/update_dense_34/bias/ApplyGradientDescent\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dense_34/bias)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value dense_34/bias\n\t [[{{node dense_34/bias/read}} = Identity[T=DT_FLOAT, _class=[\"loc:@GradientDescent/update_dense_34/bias/ApplyGradientDescent\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dense_34/bias)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-c17d2a89db37>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'step: {}, loss: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1306\u001b[0m           self._config.experimental.client_handles_error_formatting):\n\u001b[1;32m   1307\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value dense_34/bias\n\t [[{{node dense_34/bias/read}} = Identity[T=DT_FLOAT, _class=[\"loc:@GradientDescent/update_dense_34/bias/ApplyGradientDescent\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dense_34/bias)]]\n\nCaused by op 'dense_34/bias/read', defined at:\n  File \"/home/fwani/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/fwani/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-32-4f9e0b068a7b>\", line 5, in <module>\n    out = tf.layers.dense(layer4, units=1)  # label = 0 or 1\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/core.py\", line 184, in dense\n    return layer.apply(inputs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 828, in apply\n    return self.__call__(inputs, *args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 364, in __call__\n    outputs = super(Layer, self).__call__(inputs, *args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 759, in __call__\n    self.build(input_shapes)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py\", line 930, in build\n    trainable=True)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\", line 278, in add_weight\n    getter=vs.get_variable)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\", line 586, in add_weight\n    aggregation=aggregation)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py\", line 591, in _add_variable_with_custom_getter\n    **kwargs_for_getter)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1484, in get_variable\n    aggregation=aggregation)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 1234, in get_variable\n    aggregation=aggregation)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 538, in get_variable\n    aggregation=aggregation)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 492, in _true_getter\n    aggregation=aggregation)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 920, in _get_single_variable\n    aggregation=aggregation)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 145, in __call__\n    return cls._variable_call(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 141, in _variable_call\n    aggregation=aggregation)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 120, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2441, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 147, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1104, in __init__\n    constraint=constraint)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1266, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 81, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3354, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value dense_34/bias\n\t [[{{node dense_34/bias/read}} = Identity[T=DT_FLOAT, _class=[\"loc:@GradientDescent/update_dense_34/bias/ApplyGradientDescent\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](dense_34/bias)]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    for i in range(10):\n",
    "        _, loss_ = sess.run([train_op, loss])\n",
    "        print('step: {}, loss: {}'.format(i, loss_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## success in 10 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 0.8139494061470032\n",
      "step: 1, loss: 0.763070821762085\n",
      "step: 2, loss: 0.716289758682251\n",
      "step: 3, loss: 0.6722797155380249\n",
      "step: 4, loss: 0.6458951234817505\n",
      "step: 5, loss: 0.6229209899902344\n",
      "step: 6, loss: 0.6000803709030151\n",
      "step: 7, loss: 0.577208399772644\n",
      "step: 8, loss: 0.5541918277740479\n",
      "step: 9, loss: 0.5423738956451416\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(10):\n",
    "        _, loss_ = sess.run([train_op, loss])\n",
    "        print('step: {}, loss: {}'.format(i, loss_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iteration is too small than training, because of data size is 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 0.8429542779922485\n",
      "step: 1, loss: 0.7703009247779846\n",
      "step: 2, loss: 0.7157442569732666\n",
      "step: 3, loss: 0.6781694293022156\n",
      "step: 4, loss: 0.6407896280288696\n",
      "step: 5, loss: 0.6162813901901245\n",
      "step: 6, loss: 0.5960057973861694\n",
      "step: 7, loss: 0.585128664970398\n",
      "step: 8, loss: 0.5667250156402588\n",
      "step: 9, loss: 0.550173282623291\n",
      "step: 10, loss: 0.5378299951553345\n",
      "step: 11, loss: 0.5170921087265015\n",
      "step: 12, loss: 0.4756893217563629\n",
      "step: 13, loss: 0.44194382429122925\n",
      "step: 14, loss: 0.4186842441558838\n",
      "step: 15, loss: 0.3920941948890686\n",
      "step: 16, loss: 0.3724633455276489\n",
      "step: 17, loss: 0.3583548069000244\n",
      "step: 18, loss: 0.33775025606155396\n",
      "step: 19, loss: 0.3174150586128235\n",
      "step: 20, loss: 0.29897332191467285\n",
      "step: 21, loss: 0.29084599018096924\n",
      "step: 22, loss: 0.2710840106010437\n",
      "step: 23, loss: 0.2539535164833069\n",
      "step: 24, loss: 0.24137821793556213\n",
      "step: 25, loss: 0.2302323281764984\n",
      "step: 26, loss: 0.21909108757972717\n",
      "step: 27, loss: 0.20452871918678284\n",
      "step: 28, loss: 0.19494177401065826\n",
      "step: 29, loss: 0.1842018961906433\n",
      "step: 30, loss: 0.17666426301002502\n",
      "step: 31, loss: 0.16542702913284302\n",
      "step: 32, loss: 0.1567911058664322\n",
      "step: 33, loss: 0.14965927600860596\n",
      "step: 34, loss: 0.14144498109817505\n",
      "step: 35, loss: 0.13530072569847107\n",
      "step: 36, loss: 0.12948951125144958\n",
      "step: 37, loss: 0.12349949032068253\n",
      "step: 38, loss: 0.11828507483005524\n",
      "step: 39, loss: 0.11223103106021881\n",
      "step: 40, loss: 0.10731390863656998\n",
      "step: 41, loss: 0.10259900987148285\n",
      "step: 42, loss: 0.09878434985876083\n",
      "step: 43, loss: 0.09403486549854279\n",
      "step: 44, loss: 0.09027455747127533\n",
      "step: 45, loss: 0.086637482047081\n",
      "step: 46, loss: 0.08274830132722855\n",
      "step: 47, loss: 0.07965216040611267\n",
      "step: 48, loss: 0.0764312595129013\n",
      "step: 49, loss: 0.07348404824733734\n"
     ]
    },
    {
     "ename": "OutOfRangeError",
     "evalue": "End of sequence\n\t [[{{node IteratorGetNext}} = IteratorGetNext[output_shapes=[[?]], output_types=[DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator)]]\n\nCaused by op 'IteratorGetNext', defined at:\n  File \"/home/fwani/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/fwani/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-f5651d65ec16>\", line 1, in <module>\n    dataset = tf.data.TextLineDataset('./up_down_dataset.csv')    .batch(20)    .make_one_shot_iterator()    .get_next()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 420, in get_next\n    name=name)), self._output_types,\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 2069, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nOutOfRangeError (see above for traceback): End of sequence\n\t [[{{node IteratorGetNext}} = IteratorGetNext[output_shapes=[[?]], output_types=[DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence\n\t [[{{node IteratorGetNext}} = IteratorGetNext[output_shapes=[[?]], output_types=[DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-50728b14dc22>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'step: {}, loss: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1306\u001b[0m           self._config.experimental.client_handles_error_formatting):\n\u001b[1;32m   1307\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOutOfRangeError\u001b[0m: End of sequence\n\t [[{{node IteratorGetNext}} = IteratorGetNext[output_shapes=[[?]], output_types=[DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator)]]\n\nCaused by op 'IteratorGetNext', defined at:\n  File \"/home/fwani/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/fwani/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-2-f5651d65ec16>\", line 1, in <module>\n    dataset = tf.data.TextLineDataset('./up_down_dataset.csv')    .batch(20)    .make_one_shot_iterator()    .get_next()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/data/ops/iterator_ops.py\", line 420, in get_next\n    name=name)), self._output_types,\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_dataset_ops.py\", line 2069, in iterator_get_next\n    output_shapes=output_shapes, name=name)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nOutOfRangeError (see above for traceback): End of sequence\n\t [[{{node IteratorGetNext}} = IteratorGetNext[output_shapes=[[?]], output_types=[DT_STRING], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](OneShotIterator)]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(1000):\n",
    "        _, loss_ = sess.run([train_op, loss])\n",
    "        print('step: {}, loss: {}'.format(i, loss_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sucess fitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# repeat(step_repeat_number)\n",
    "dataset = tf.data.TextLineDataset('./up_down_dataset.csv')\\\n",
    "    .batch(20)\\\n",
    "    .repeat(9999)\\\n",
    "    .make_one_shot_iterator()\\\n",
    "    .get_next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines = tf.decode_csv(dataset, record_defaults=[[0]]*11)\n",
    "feature = tf.stack(lines[:-1], axis=1)\n",
    "label = tf.expand_dims(lines[-1], axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature = tf.cast(feature, tf.float32)\n",
    "label = tf.cast(label, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "layer1 = tf.layers.dense(feature, units=10, activation=tf.nn.relu) # units = the number of node\n",
    "layer2 = tf.layers.dense(layer1, units=10, activation=tf.nn.relu)\n",
    "layer3 = tf.layers.dense(layer2, units=10, activation=tf.nn.relu)\n",
    "layer4 = tf.layers.dense(layer3, units=10, activation=tf.nn.relu)\n",
    "out = tf.layers.dense(layer4, units=1)  # label = 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss function\n",
    "loss = tf.losses.sigmoid_cross_entropy(label, out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_op = tf.train.GradientDescentOptimizer(1e-2).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# prediction\n",
    "pred = tf.nn.sigmoid(out)  # number of 0~1 \n",
    "# accuracy\n",
    "acc = tf.metrics.accuracy(label, tf.round(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## accuracy uninitailized error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "FailedPreconditionError",
     "evalue": "Attempting to use uninitialized value accuracy/total\n\t [[{{node accuracy/total/read}} = Identity[T=DT_FLOAT, _class=[\"loc:@accuracy/AssignAdd\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](accuracy/total)]]\n\nCaused by op 'accuracy/total/read', defined at:\n  File \"/home/fwani/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/fwani/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-45-70d3690d6342>\", line 4, in <module>\n    acc = tf.metrics.accuracy(label, pred)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py\", line 478, in accuracy\n    name or 'accuracy')\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py\", line 388, in mean\n    total = metric_variable([], dtypes.float32, name='total')\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py\", line 86, in metric_variable\n    name=name)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 145, in __call__\n    return cls._variable_call(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 141, in _variable_call\n    aggregation=aggregation)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 120, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2441, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 147, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1104, in __init__\n    constraint=constraint)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1266, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 81, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3354, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value accuracy/total\n\t [[{{node accuracy/total/read}} = Identity[T=DT_FLOAT, _class=[\"loc:@accuracy/AssignAdd\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](accuracy/total)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1291\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1276\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1277\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1366\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1367\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1368\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value accuracy/total\n\t [[{{node accuracy/total/read}} = Identity[T=DT_FLOAT, _class=[\"loc:@accuracy/AssignAdd\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](accuracy/total)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-1624653a7200>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'step: {}, loss: {}, accuracy: {}'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    885\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    886\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 887\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    888\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    889\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1108\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1109\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1110\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1111\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1284\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1285\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1286\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1287\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1288\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1306\u001b[0m           self._config.experimental.client_handles_error_formatting):\n\u001b[1;32m   1307\u001b[0m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1308\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1309\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1310\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFailedPreconditionError\u001b[0m: Attempting to use uninitialized value accuracy/total\n\t [[{{node accuracy/total/read}} = Identity[T=DT_FLOAT, _class=[\"loc:@accuracy/AssignAdd\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](accuracy/total)]]\n\nCaused by op 'accuracy/total/read', defined at:\n  File \"/home/fwani/anaconda3/lib/python3.6/runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"/home/fwani/anaconda3/lib/python3.6/runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py\", line 658, in launch_instance\n    app.start()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py\", line 477, in start\n    ioloop.IOLoop.instance().start()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 235, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py\", line 196, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py\", line 533, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2698, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2802, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2862, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-45-70d3690d6342>\", line 4, in <module>\n    acc = tf.metrics.accuracy(label, pred)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py\", line 478, in accuracy\n    name or 'accuracy')\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py\", line 388, in mean\n    total = metric_variable([], dtypes.float32, name='total')\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/metrics_impl.py\", line 86, in metric_variable\n    name=name)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 145, in __call__\n    return cls._variable_call(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 141, in _variable_call\n    aggregation=aggregation)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 120, in <lambda>\n    previous_getter = lambda **kwargs: default_variable_creator(None, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\", line 2441, in default_variable_creator\n    expected_shape=expected_shape, import_scope=import_scope)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 147, in __call__\n    return super(VariableMetaclass, cls).__call__(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1104, in __init__\n    constraint=constraint)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variables.py\", line 1266, in _init_from_args\n    self._snapshot = array_ops.identity(self._variable, name=\"read\")\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/array_ops.py\", line 81, in identity\n    return gen_array_ops.identity(input, name=name)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 3354, in identity\n    \"Identity\", input=input, name=name)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/deprecation.py\", line 488, in new_func\n    return func(*args, **kwargs)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 3272, in create_op\n    op_def=op_def)\n  File \"/home/fwani/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/ops.py\", line 1768, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nFailedPreconditionError (see above for traceback): Attempting to use uninitialized value accuracy/total\n\t [[{{node accuracy/total/read}} = Identity[T=DT_FLOAT, _class=[\"loc:@accuracy/AssignAdd\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](accuracy/total)]]\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for i in range(1000):\n",
    "        _, loss_, acc_ = sess.run([train_op, loss, acc])\n",
    "        print('step: {}, loss: {}, accuracy: {}'.format(i, loss_, acc_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 0, loss: 0.6548398733139038, accuracy: (0.0, 0.5)\n",
      "step: 1, loss: 0.5978040099143982, accuracy: (0.5, 0.75)\n",
      "step: 2, loss: 0.571531355381012, accuracy: (0.75, 0.83333331)\n",
      "step: 3, loss: 0.563373327255249, accuracy: (0.83333331, 0.875)\n",
      "step: 4, loss: 0.5549245476722717, accuracy: (0.875, 0.89999998)\n",
      "step: 5, loss: 0.546392560005188, accuracy: (0.89999998, 0.91666669)\n",
      "step: 6, loss: 0.5377994179725647, accuracy: (0.91666669, 0.9285714)\n",
      "step: 7, loss: 0.529557466506958, accuracy: (0.9285714, 0.9375)\n",
      "step: 8, loss: 0.5215388536453247, accuracy: (0.9375, 0.94444442)\n",
      "step: 9, loss: 0.5135309100151062, accuracy: (0.94444442, 0.94999999)\n",
      "step: 10, loss: 0.5055587887763977, accuracy: (0.94999999, 0.95454544)\n",
      "step: 11, loss: 0.49764758348464966, accuracy: (0.95454544, 0.95833331)\n",
      "step: 12, loss: 0.4898219108581543, accuracy: (0.95833331, 0.96153843)\n",
      "step: 13, loss: 0.4825829863548279, accuracy: (0.96153843, 0.96428573)\n",
      "step: 14, loss: 0.4760782718658447, accuracy: (0.96428573, 0.96666664)\n",
      "step: 15, loss: 0.46964773535728455, accuracy: (0.96666664, 0.96875)\n",
      "step: 16, loss: 0.46330517530441284, accuracy: (0.96875, 0.97058821)\n",
      "step: 17, loss: 0.45706337690353394, accuracy: (0.97058821, 0.97222221)\n",
      "step: 18, loss: 0.4509333670139313, accuracy: (0.97222221, 0.97368419)\n",
      "step: 19, loss: 0.4449252188205719, accuracy: (0.97368419, 0.97500002)\n",
      "step: 20, loss: 0.4390473961830139, accuracy: (0.97500002, 0.97619045)\n",
      "step: 21, loss: 0.4333067536354065, accuracy: (0.97619045, 0.97727275)\n",
      "step: 22, loss: 0.4277086853981018, accuracy: (0.97727275, 0.97826087)\n",
      "step: 23, loss: 0.4222570061683655, accuracy: (0.97826087, 0.97916669)\n",
      "step: 24, loss: 0.4169541001319885, accuracy: (0.97916669, 0.98000002)\n",
      "step: 25, loss: 0.4118008017539978, accuracy: (0.98000002, 0.98076922)\n",
      "step: 26, loss: 0.40679702162742615, accuracy: (0.98076922, 0.98148149)\n",
      "step: 27, loss: 0.40194129943847656, accuracy: (0.98148149, 0.98214287)\n",
      "step: 28, loss: 0.3972594738006592, accuracy: (0.98214287, 0.98275864)\n",
      "step: 29, loss: 0.3927837610244751, accuracy: (0.98275864, 0.98333335)\n",
      "step: 30, loss: 0.38844209909439087, accuracy: (0.98333335, 0.98387098)\n",
      "step: 31, loss: 0.38422977924346924, accuracy: (0.98387098, 0.984375)\n",
      "step: 32, loss: 0.38014164566993713, accuracy: (0.984375, 0.9848485)\n",
      "step: 33, loss: 0.37617242336273193, accuracy: (0.9848485, 0.9852941)\n",
      "step: 34, loss: 0.3723161220550537, accuracy: (0.9852941, 0.98571426)\n",
      "step: 35, loss: 0.3685668706893921, accuracy: (0.98571426, 0.9861111)\n",
      "step: 36, loss: 0.36491867899894714, accuracy: (0.9861111, 0.98648649)\n",
      "step: 37, loss: 0.36136528849601746, accuracy: (0.98648649, 0.9868421)\n",
      "step: 38, loss: 0.3579007387161255, accuracy: (0.9868421, 0.98717946)\n",
      "step: 39, loss: 0.354518860578537, accuracy: (0.98717946, 0.98750001)\n",
      "step: 40, loss: 0.3512137830257416, accuracy: (0.98750001, 0.98780489)\n",
      "step: 41, loss: 0.34797972440719604, accuracy: (0.98780489, 0.98809522)\n",
      "step: 42, loss: 0.3448109030723572, accuracy: (0.98809522, 0.98837209)\n",
      "step: 43, loss: 0.3417018949985504, accuracy: (0.98837209, 0.98863637)\n",
      "step: 44, loss: 0.3385969400405884, accuracy: (0.98863637, 0.98888886)\n",
      "step: 45, loss: 0.33498355746269226, accuracy: (0.98888886, 0.98913044)\n",
      "step: 46, loss: 0.33151277899742126, accuracy: (0.98913044, 0.9893617)\n",
      "step: 47, loss: 0.32813555002212524, accuracy: (0.9893617, 0.98958331)\n",
      "step: 48, loss: 0.3248522877693176, accuracy: (0.98958331, 0.98979592)\n",
      "step: 49, loss: 0.3216678202152252, accuracy: (0.98979592, 0.99000001)\n",
      "step: 50, loss: 0.31853407621383667, accuracy: (0.99000001, 0.99019605)\n",
      "step: 51, loss: 0.3154870569705963, accuracy: (0.99019605, 0.99038464)\n",
      "step: 52, loss: 0.3124706447124481, accuracy: (0.99038464, 0.99056602)\n",
      "step: 53, loss: 0.30952298641204834, accuracy: (0.99056602, 0.99074072)\n",
      "step: 54, loss: 0.30659401416778564, accuracy: (0.99074072, 0.9909091)\n",
      "step: 55, loss: 0.3037157654762268, accuracy: (0.9909091, 0.9910714)\n",
      "step: 56, loss: 0.30085092782974243, accuracy: (0.9910714, 0.99122804)\n",
      "step: 57, loss: 0.2980106770992279, accuracy: (0.99122804, 0.99137932)\n",
      "step: 58, loss: 0.29519152641296387, accuracy: (0.99137932, 0.99152541)\n",
      "step: 59, loss: 0.2923753559589386, accuracy: (0.99152541, 0.99166667)\n",
      "step: 60, loss: 0.2895832061767578, accuracy: (0.99166667, 0.99180329)\n",
      "step: 61, loss: 0.2867857813835144, accuracy: (0.99180329, 0.99193549)\n",
      "step: 62, loss: 0.2839881181716919, accuracy: (0.99193549, 0.99206346)\n",
      "step: 63, loss: 0.2811889350414276, accuracy: (0.99206346, 0.9921875)\n",
      "step: 64, loss: 0.2783896028995514, accuracy: (0.9921875, 0.99230766)\n",
      "step: 65, loss: 0.27556556463241577, accuracy: (0.99230766, 0.99242425)\n",
      "step: 66, loss: 0.2727275490760803, accuracy: (0.99242425, 0.99253732)\n",
      "step: 67, loss: 0.26988351345062256, accuracy: (0.99253732, 0.99264705)\n",
      "step: 68, loss: 0.2670212984085083, accuracy: (0.99264705, 0.99275362)\n",
      "step: 69, loss: 0.2641318142414093, accuracy: (0.99275362, 0.99285716)\n",
      "step: 70, loss: 0.26122233271598816, accuracy: (0.99285716, 0.99295777)\n",
      "step: 71, loss: 0.2583039700984955, accuracy: (0.99295777, 0.99305558)\n",
      "step: 72, loss: 0.25534459948539734, accuracy: (0.99305558, 0.99315071)\n",
      "step: 73, loss: 0.2523583769798279, accuracy: (0.99315071, 0.99324322)\n",
      "step: 74, loss: 0.24936027824878693, accuracy: (0.99324322, 0.99333334)\n",
      "step: 75, loss: 0.2463195025920868, accuracy: (0.99333334, 0.99342108)\n",
      "step: 76, loss: 0.24324651062488556, accuracy: (0.99342108, 0.99350649)\n",
      "step: 77, loss: 0.24015812575817108, accuracy: (0.99350649, 0.99358976)\n",
      "step: 78, loss: 0.2370261698961258, accuracy: (0.99358976, 0.99367088)\n",
      "step: 79, loss: 0.23385915160179138, accuracy: (0.99367088, 0.99374998)\n",
      "step: 80, loss: 0.23067709803581238, accuracy: (0.99374998, 0.99382716)\n",
      "step: 81, loss: 0.2274511754512787, accuracy: (0.99382716, 0.99390244)\n",
      "step: 82, loss: 0.2241969108581543, accuracy: (0.99390244, 0.99397588)\n",
      "step: 83, loss: 0.22091785073280334, accuracy: (0.99397588, 0.99404764)\n",
      "step: 84, loss: 0.21759209036827087, accuracy: (0.99404764, 0.99411762)\n",
      "step: 85, loss: 0.21424369513988495, accuracy: (0.99411762, 0.99418604)\n",
      "step: 86, loss: 0.21086916327476501, accuracy: (0.99418604, 0.99425286)\n",
      "step: 87, loss: 0.20751211047172546, accuracy: (0.99425286, 0.99431819)\n",
      "step: 88, loss: 0.20420017838478088, accuracy: (0.99431819, 0.99438202)\n",
      "step: 89, loss: 0.20086164772510529, accuracy: (0.99438202, 0.99444443)\n",
      "step: 90, loss: 0.19749373197555542, accuracy: (0.99444443, 0.99450547)\n",
      "step: 91, loss: 0.19410340487957, accuracy: (0.99450547, 0.99456519)\n",
      "step: 92, loss: 0.1906992644071579, accuracy: (0.99456519, 0.99462366)\n",
      "step: 93, loss: 0.187515527009964, accuracy: (0.99462366, 0.99468082)\n",
      "step: 94, loss: 0.18415316939353943, accuracy: (0.99468082, 0.99473685)\n",
      "step: 95, loss: 0.1807948648929596, accuracy: (0.99473685, 0.99479169)\n",
      "step: 96, loss: 0.17753620445728302, accuracy: (0.99479169, 0.99484539)\n",
      "step: 97, loss: 0.17406818270683289, accuracy: (0.99484539, 0.99489796)\n",
      "step: 98, loss: 0.17086893320083618, accuracy: (0.99489796, 0.99494952)\n",
      "step: 99, loss: 0.16755953431129456, accuracy: (0.99494952, 0.995)\n",
      "step: 100, loss: 0.1642863154411316, accuracy: (0.995, 0.99504948)\n",
      "step: 101, loss: 0.16116760671138763, accuracy: (0.99504948, 0.99509805)\n",
      "step: 102, loss: 0.15782442688941956, accuracy: (0.99509805, 0.99514562)\n",
      "step: 103, loss: 0.15465041995048523, accuracy: (0.99514562, 0.99519229)\n",
      "step: 104, loss: 0.15151551365852356, accuracy: (0.99519229, 0.99523807)\n",
      "step: 105, loss: 0.14821745455265045, accuracy: (0.99523807, 0.99528301)\n",
      "step: 106, loss: 0.1451636105775833, accuracy: (0.99528301, 0.99532712)\n",
      "step: 107, loss: 0.14198574423789978, accuracy: (0.99532712, 0.99537039)\n",
      "step: 108, loss: 0.13881058990955353, accuracy: (0.99537039, 0.99541283)\n",
      "step: 109, loss: 0.13588477671146393, accuracy: (0.99541283, 0.99545455)\n",
      "step: 110, loss: 0.1326972246170044, accuracy: (0.99545455, 0.9954955)\n",
      "step: 111, loss: 0.12975110113620758, accuracy: (0.9954955, 0.99553573)\n",
      "step: 112, loss: 0.1267419308423996, accuracy: (0.99553573, 0.99557525)\n",
      "step: 113, loss: 0.12373100221157074, accuracy: (0.99557525, 0.99561405)\n",
      "step: 114, loss: 0.1209399551153183, accuracy: (0.99561405, 0.9956522)\n",
      "step: 115, loss: 0.11796732246875763, accuracy: (0.9956522, 0.99568963)\n",
      "step: 116, loss: 0.11521802097558975, accuracy: (0.99568963, 0.99572647)\n",
      "step: 117, loss: 0.11239410936832428, accuracy: (0.99572647, 0.99576271)\n",
      "step: 118, loss: 0.10962361097335815, accuracy: (0.99576271, 0.99579829)\n",
      "step: 119, loss: 0.10699828714132309, accuracy: (0.99579829, 0.99583334)\n",
      "step: 120, loss: 0.10425637662410736, accuracy: (0.99583334, 0.99586779)\n",
      "step: 121, loss: 0.10175801813602448, accuracy: (0.99586779, 0.99590164)\n",
      "step: 122, loss: 0.09915971755981445, accuracy: (0.99590164, 0.99593496)\n",
      "step: 123, loss: 0.09665186703205109, accuracy: (0.99593496, 0.99596775)\n",
      "step: 124, loss: 0.09428435564041138, accuracy: (0.99596775, 0.99599999)\n",
      "step: 125, loss: 0.09178591519594193, accuracy: (0.99599999, 0.99603176)\n",
      "step: 126, loss: 0.08956123143434525, accuracy: (0.99603176, 0.99606299)\n",
      "step: 127, loss: 0.08719290792942047, accuracy: (0.99606299, 0.99609375)\n",
      "step: 128, loss: 0.0849953442811966, accuracy: (0.99609375, 0.99612403)\n",
      "step: 129, loss: 0.08280729502439499, accuracy: (0.99612403, 0.99615383)\n",
      "step: 130, loss: 0.08065373450517654, accuracy: (0.99615383, 0.99618322)\n",
      "step: 131, loss: 0.07865587621927261, accuracy: (0.99618322, 0.99621212)\n",
      "step: 132, loss: 0.07656341046094894, accuracy: (0.99621212, 0.99624062)\n",
      "step: 133, loss: 0.07468605786561966, accuracy: (0.99624062, 0.99626863)\n",
      "step: 134, loss: 0.07271938771009445, accuracy: (0.99626863, 0.99629629)\n",
      "step: 135, loss: 0.07088882476091385, accuracy: (0.99629629, 0.99632353)\n",
      "step: 136, loss: 0.06909533590078354, accuracy: (0.99632353, 0.99635035)\n",
      "step: 137, loss: 0.06729370355606079, accuracy: (0.99635035, 0.99637681)\n",
      "step: 138, loss: 0.06565812230110168, accuracy: (0.99637681, 0.99640286)\n",
      "step: 139, loss: 0.06394616514444351, accuracy: (0.99640286, 0.99642855)\n",
      "step: 140, loss: 0.06238202005624771, accuracy: (0.99642855, 0.99645388)\n",
      "step: 141, loss: 0.06079862266778946, accuracy: (0.99645388, 0.99647886)\n",
      "step: 142, loss: 0.05926660820841789, accuracy: (0.99647886, 0.99650347)\n",
      "step: 143, loss: 0.05782574415206909, accuracy: (0.99650347, 0.99652779)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 144, loss: 0.05635932832956314, accuracy: (0.99652779, 0.99655175)\n",
      "step: 145, loss: 0.055012501776218414, accuracy: (0.99655175, 0.99657536)\n",
      "step: 146, loss: 0.05364419147372246, accuracy: (0.99657536, 0.99659866)\n",
      "step: 147, loss: 0.052337754517793655, accuracy: (0.99659866, 0.99662161)\n",
      "step: 148, loss: 0.05109497159719467, accuracy: (0.99662161, 0.99664432)\n",
      "step: 149, loss: 0.04982944577932358, accuracy: (0.99664432, 0.99666667)\n",
      "step: 150, loss: 0.04867793619632721, accuracy: (0.99666667, 0.99668872)\n",
      "step: 151, loss: 0.04749511554837227, accuracy: (0.99668872, 0.99671054)\n",
      "step: 152, loss: 0.046384964138269424, accuracy: (0.99671054, 0.996732)\n",
      "step: 153, loss: 0.0453086793422699, accuracy: (0.996732, 0.99675328)\n",
      "step: 154, loss: 0.0442253053188324, accuracy: (0.99675328, 0.9967742)\n",
      "step: 155, loss: 0.04324324056506157, accuracy: (0.9967742, 0.99679488)\n",
      "step: 156, loss: 0.04222812131047249, accuracy: (0.99679488, 0.99681526)\n",
      "step: 157, loss: 0.041281793266534805, accuracy: (0.99681526, 0.99683547)\n",
      "step: 158, loss: 0.04035079479217529, accuracy: (0.99683547, 0.99685532)\n",
      "step: 159, loss: 0.03943052887916565, accuracy: (0.99685532, 0.99687499)\n",
      "step: 160, loss: 0.03858103230595589, accuracy: (0.99687499, 0.99689442)\n",
      "step: 161, loss: 0.03770869970321655, accuracy: (0.99689442, 0.99691355)\n",
      "step: 162, loss: 0.03689675033092499, accuracy: (0.99691355, 0.99693251)\n",
      "step: 163, loss: 0.036098405718803406, accuracy: (0.99693251, 0.99695122)\n",
      "step: 164, loss: 0.03531832620501518, accuracy: (0.99695122, 0.9969697)\n",
      "step: 165, loss: 0.03458087146282196, accuracy: (0.9969697, 0.99698794)\n",
      "step: 166, loss: 0.0338321290910244, accuracy: (0.99698794, 0.997006)\n",
      "step: 167, loss: 0.03314236178994179, accuracy: (0.997006, 0.99702382)\n",
      "step: 168, loss: 0.03244396299123764, accuracy: (0.99702382, 0.9970414)\n",
      "step: 169, loss: 0.03177377209067345, accuracy: (0.9970414, 0.99705881)\n",
      "step: 170, loss: 0.03113747015595436, accuracy: (0.99705881, 0.99707603)\n",
      "step: 171, loss: 0.0305000189691782, accuracy: (0.99707603, 0.99709302)\n",
      "step: 172, loss: 0.02990150824189186, accuracy: (0.99709302, 0.99710983)\n",
      "step: 173, loss: 0.02929970994591713, accuracy: (0.99710983, 0.99712646)\n",
      "step: 174, loss: 0.02872258983552456, accuracy: (0.99712646, 0.99714285)\n",
      "step: 175, loss: 0.02816825546324253, accuracy: (0.99714285, 0.99715906)\n",
      "step: 176, loss: 0.027611246332526207, accuracy: (0.99715906, 0.99717516)\n",
      "step: 177, loss: 0.027102326974272728, accuracy: (0.99717516, 0.99719101)\n",
      "step: 178, loss: 0.026579027995467186, accuracy: (0.99719101, 0.99720669)\n",
      "step: 179, loss: 0.0260805431753397, accuracy: (0.99720669, 0.99722224)\n",
      "step: 180, loss: 0.025596585124731064, accuracy: (0.99722224, 0.99723756)\n",
      "step: 181, loss: 0.0251139048486948, accuracy: (0.99723756, 0.99725276)\n",
      "step: 182, loss: 0.02467019110918045, accuracy: (0.99725276, 0.99726778)\n",
      "step: 183, loss: 0.024212006479501724, accuracy: (0.99726778, 0.99728262)\n",
      "step: 184, loss: 0.023781757801771164, accuracy: (0.99728262, 0.99729729)\n",
      "step: 185, loss: 0.023357458412647247, accuracy: (0.99729729, 0.99731183)\n",
      "step: 186, loss: 0.02293662540614605, accuracy: (0.99731183, 0.9973262)\n",
      "step: 187, loss: 0.022549210116267204, accuracy: (0.9973262, 0.99734044)\n",
      "step: 188, loss: 0.022152196615934372, accuracy: (0.99734044, 0.99735451)\n",
      "step: 189, loss: 0.021771127358078957, accuracy: (0.99735451, 0.9973684)\n",
      "step: 190, loss: 0.021405663341283798, accuracy: (0.9973684, 0.99738222)\n",
      "step: 191, loss: 0.021035736426711082, accuracy: (0.99738222, 0.99739581)\n",
      "step: 192, loss: 0.020693494006991386, accuracy: (0.99739581, 0.99740934)\n",
      "step: 193, loss: 0.020342810079455376, accuracy: (0.99740934, 0.9974227)\n",
      "step: 194, loss: 0.020008716732263565, accuracy: (0.9974227, 0.99743587)\n",
      "step: 195, loss: 0.019688325002789497, accuracy: (0.99743587, 0.99744898)\n",
      "step: 196, loss: 0.019361773505806923, accuracy: (0.99744898, 0.99746192)\n",
      "step: 197, loss: 0.01905999146401882, accuracy: (0.99746192, 0.99747473)\n",
      "step: 198, loss: 0.018754124641418457, accuracy: (0.99747473, 0.99748743)\n",
      "step: 199, loss: 0.01845869980752468, accuracy: (0.99748743, 0.9975)\n",
      "step: 200, loss: 0.01817336305975914, accuracy: (0.9975, 0.99751246)\n",
      "step: 201, loss: 0.017886394634842873, accuracy: (0.99751246, 0.99752474)\n",
      "step: 202, loss: 0.017617177218198776, accuracy: (0.99752474, 0.99753696)\n",
      "step: 203, loss: 0.01734788715839386, accuracy: (0.99753696, 0.997549)\n",
      "step: 204, loss: 0.01708408258855343, accuracy: (0.997549, 0.99756098)\n",
      "step: 205, loss: 0.016833355650305748, accuracy: (0.99756098, 0.99757284)\n",
      "step: 206, loss: 0.016579654067754745, accuracy: (0.99757284, 0.99758452)\n",
      "step: 207, loss: 0.01634245738387108, accuracy: (0.99758452, 0.99759614)\n",
      "step: 208, loss: 0.0161008108407259, accuracy: (0.99759614, 0.99760765)\n",
      "step: 209, loss: 0.01586536504328251, accuracy: (0.99760765, 0.99761903)\n",
      "step: 210, loss: 0.01564250886440277, accuracy: (0.99761903, 0.99763036)\n",
      "step: 211, loss: 0.015415536239743233, accuracy: (0.99763036, 0.9976415)\n",
      "step: 212, loss: 0.015199394896626472, accuracy: (0.9976415, 0.99765259)\n",
      "step: 213, loss: 0.014988332986831665, accuracy: (0.99765259, 0.99766356)\n",
      "step: 214, loss: 0.014776323921978474, accuracy: (0.99766356, 0.99767441)\n",
      "step: 215, loss: 0.014578031376004219, accuracy: (0.99767441, 0.99768519)\n",
      "step: 216, loss: 0.014377566054463387, accuracy: (0.99768519, 0.99769586)\n",
      "step: 217, loss: 0.014181460253894329, accuracy: (0.99769586, 0.99770641)\n",
      "step: 218, loss: 0.013992607593536377, accuracy: (0.99770641, 0.9977169)\n",
      "step: 219, loss: 0.013803604058921337, accuracy: (0.9977169, 0.99772727)\n",
      "step: 220, loss: 0.013624049723148346, accuracy: (0.99772727, 0.99773753)\n",
      "step: 221, loss: 0.013443579897284508, accuracy: (0.99773753, 0.99774772)\n",
      "step: 222, loss: 0.013266561552882195, accuracy: (0.99774772, 0.99775785)\n",
      "step: 223, loss: 0.013099797070026398, accuracy: (0.99775785, 0.99776787)\n",
      "step: 224, loss: 0.012928081676363945, accuracy: (0.99776787, 0.99777776)\n",
      "step: 225, loss: 0.012764694169163704, accuracy: (0.99777776, 0.99778759)\n",
      "step: 226, loss: 0.012604661285877228, accuracy: (0.99778759, 0.99779737)\n",
      "step: 227, loss: 0.012443666346371174, accuracy: (0.99779737, 0.99780703)\n",
      "step: 228, loss: 0.012292575091123581, accuracy: (0.99780703, 0.99781662)\n",
      "step: 229, loss: 0.012139733880758286, accuracy: (0.99781662, 0.9978261)\n",
      "step: 230, loss: 0.011990031227469444, accuracy: (0.9978261, 0.99783552)\n",
      "step: 231, loss: 0.01184641383588314, accuracy: (0.99783552, 0.99784482)\n",
      "step: 232, loss: 0.011702964082360268, accuracy: (0.99784482, 0.99785405)\n",
      "step: 233, loss: 0.011565524153411388, accuracy: (0.99785405, 0.99786323)\n",
      "step: 234, loss: 0.011430042795836926, accuracy: (0.99786323, 0.99787235)\n",
      "step: 235, loss: 0.011294219642877579, accuracy: (0.99787235, 0.99788135)\n",
      "step: 236, loss: 0.011166234500706196, accuracy: (0.99788135, 0.99789029)\n",
      "step: 237, loss: 0.011039766483008862, accuracy: (0.99789029, 0.99789917)\n",
      "step: 238, loss: 0.010911926627159119, accuracy: (0.99789917, 0.99790794)\n",
      "step: 239, loss: 0.010787726379930973, accuracy: (0.99790794, 0.99791664)\n",
      "step: 240, loss: 0.010666314512491226, accuracy: (0.99791664, 0.99792528)\n",
      "step: 241, loss: 0.010552878491580486, accuracy: (0.99792528, 0.99793386)\n",
      "step: 242, loss: 0.010430848225951195, accuracy: (0.99793386, 0.99794239)\n",
      "step: 243, loss: 0.01031635981053114, accuracy: (0.99794239, 0.99795079)\n",
      "step: 244, loss: 0.01020580343902111, accuracy: (0.99795079, 0.9979592)\n",
      "step: 245, loss: 0.01009236741811037, accuracy: (0.9979592, 0.99796748)\n",
      "step: 246, loss: 0.009988052770495415, accuracy: (0.99796748, 0.99797571)\n",
      "step: 247, loss: 0.009879877790808678, accuracy: (0.99797571, 0.99798387)\n",
      "step: 248, loss: 0.009772898629307747, accuracy: (0.99798387, 0.99799198)\n",
      "step: 249, loss: 0.009671923704445362, accuracy: (0.99799198, 0.99800003)\n",
      "step: 250, loss: 0.009572885930538177, accuracy: (0.99800003, 0.99800795)\n",
      "step: 251, loss: 0.009472167119383812, accuracy: (0.99800795, 0.99801588)\n",
      "step: 252, loss: 0.009373831562697887, accuracy: (0.99801588, 0.99802369)\n",
      "step: 253, loss: 0.009275426156818867, accuracy: (0.99802369, 0.9980315)\n",
      "step: 254, loss: 0.009185019880533218, accuracy: (0.9980315, 0.99803919)\n",
      "step: 255, loss: 0.009093026630580425, accuracy: (0.99803919, 0.99804688)\n",
      "step: 256, loss: 0.008998986333608627, accuracy: (0.99804688, 0.9980545)\n",
      "step: 257, loss: 0.008910082280635834, accuracy: (0.9980545, 0.99806201)\n",
      "step: 258, loss: 0.008820434100925922, accuracy: (0.99806201, 0.99806952)\n",
      "step: 259, loss: 0.008734742179512978, accuracy: (0.99806952, 0.99807692)\n",
      "step: 260, loss: 0.00864986889064312, accuracy: (0.99807692, 0.99808431)\n",
      "step: 261, loss: 0.008565121330320835, accuracy: (0.99808431, 0.99809158)\n",
      "step: 262, loss: 0.008484646677970886, accuracy: (0.99809158, 0.99809885)\n",
      "step: 263, loss: 0.008401943370699883, accuracy: (0.99809885, 0.99810606)\n",
      "step: 264, loss: 0.008321152068674564, accuracy: (0.99810606, 0.99811321)\n",
      "step: 265, loss: 0.008243411779403687, accuracy: (0.99811321, 0.99812031)\n",
      "step: 266, loss: 0.008166052401065826, accuracy: (0.99812031, 0.99812734)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 267, loss: 0.008090284653007984, accuracy: (0.99812734, 0.99813432)\n",
      "step: 268, loss: 0.008015456609427929, accuracy: (0.99813432, 0.99814129)\n",
      "step: 269, loss: 0.007939456962049007, accuracy: (0.99814129, 0.99814814)\n",
      "step: 270, loss: 0.00787038542330265, accuracy: (0.99814814, 0.998155)\n",
      "step: 271, loss: 0.007798282895237207, accuracy: (0.998155, 0.99816179)\n",
      "step: 272, loss: 0.007726012729108334, accuracy: (0.99816179, 0.99816847)\n",
      "step: 273, loss: 0.0076572485268116, accuracy: (0.99816847, 0.9981752)\n",
      "step: 274, loss: 0.007587317377328873, accuracy: (0.9981752, 0.99818182)\n",
      "step: 275, loss: 0.0075223566964268684, accuracy: (0.99818182, 0.99818838)\n",
      "step: 276, loss: 0.007457605563104153, accuracy: (0.99818838, 0.99819493)\n",
      "step: 277, loss: 0.007389381527900696, accuracy: (0.99819493, 0.99820143)\n",
      "step: 278, loss: 0.0073258355259895325, accuracy: (0.99820143, 0.99820787)\n",
      "step: 279, loss: 0.007261174265295267, accuracy: (0.99820787, 0.9982143)\n",
      "step: 280, loss: 0.007199225481599569, accuracy: (0.9982143, 0.99822062)\n",
      "step: 281, loss: 0.007139856927096844, accuracy: (0.99822062, 0.99822694)\n",
      "step: 282, loss: 0.007076955400407314, accuracy: (0.99822694, 0.9982332)\n",
      "step: 283, loss: 0.007016360759735107, accuracy: (0.9982332, 0.99823946)\n",
      "step: 284, loss: 0.006957758218050003, accuracy: (0.99823946, 0.9982456)\n",
      "step: 285, loss: 0.006899015046656132, accuracy: (0.9982456, 0.99825174)\n",
      "step: 286, loss: 0.006844203919172287, accuracy: (0.99825174, 0.99825782)\n",
      "step: 287, loss: 0.00678658951073885, accuracy: (0.99825782, 0.9982639)\n",
      "step: 288, loss: 0.006729333661496639, accuracy: (0.9982639, 0.99826992)\n",
      "step: 289, loss: 0.006675256881862879, accuracy: (0.99826992, 0.99827588)\n",
      "step: 290, loss: 0.0066209109500050545, accuracy: (0.99827588, 0.99828178)\n",
      "step: 291, loss: 0.006568639073520899, accuracy: (0.99828178, 0.99828768)\n",
      "step: 292, loss: 0.006515734829008579, accuracy: (0.99828768, 0.99829352)\n",
      "step: 293, loss: 0.006462567485868931, accuracy: (0.99829352, 0.9982993)\n",
      "step: 294, loss: 0.00641122180968523, accuracy: (0.9982993, 0.99830508)\n",
      "step: 295, loss: 0.006360442377626896, accuracy: (0.99830508, 0.9983108)\n",
      "step: 296, loss: 0.006310378201305866, accuracy: (0.9983108, 0.99831653)\n",
      "step: 297, loss: 0.006262398324906826, accuracy: (0.99831653, 0.99832213)\n",
      "step: 298, loss: 0.006213353015482426, accuracy: (0.99832213, 0.99832773)\n",
      "step: 299, loss: 0.0061642564833164215, accuracy: (0.99832773, 0.99833333)\n",
      "step: 300, loss: 0.0061173029243946075, accuracy: (0.99833333, 0.99833888)\n",
      "step: 301, loss: 0.006070088129490614, accuracy: (0.99833888, 0.99834436)\n",
      "step: 302, loss: 0.006023610010743141, accuracy: (0.99834436, 0.99834985)\n",
      "step: 303, loss: 0.005980873014777899, accuracy: (0.99834985, 0.99835527)\n",
      "step: 304, loss: 0.0059351325035095215, accuracy: (0.99835527, 0.99836063)\n",
      "step: 305, loss: 0.005889345891773701, accuracy: (0.99836063, 0.998366)\n",
      "step: 306, loss: 0.005846190731972456, accuracy: (0.998366, 0.99837136)\n",
      "step: 307, loss: 0.005802272818982601, accuracy: (0.99837136, 0.99837661)\n",
      "step: 308, loss: 0.005759187042713165, accuracy: (0.99837661, 0.99838185)\n",
      "step: 309, loss: 0.005718423053622246, accuracy: (0.99838185, 0.9983871)\n",
      "step: 310, loss: 0.005675808060914278, accuracy: (0.9983871, 0.99839228)\n",
      "step: 311, loss: 0.005634653382003307, accuracy: (0.99839228, 0.99839741)\n",
      "step: 312, loss: 0.00559478672221303, accuracy: (0.99839741, 0.99840254)\n",
      "step: 313, loss: 0.0055541773326694965, accuracy: (0.99840254, 0.99840766)\n",
      "step: 314, loss: 0.005514784716069698, accuracy: (0.99840766, 0.99841267)\n",
      "step: 315, loss: 0.0054760100319981575, accuracy: (0.99841267, 0.99841774)\n",
      "step: 316, loss: 0.005436557810753584, accuracy: (0.99841774, 0.99842274)\n",
      "step: 317, loss: 0.00539818312972784, accuracy: (0.99842274, 0.99842769)\n",
      "step: 318, loss: 0.005361470393836498, accuracy: (0.99842769, 0.99843258)\n",
      "step: 319, loss: 0.005323224235326052, accuracy: (0.99843258, 0.99843752)\n",
      "step: 320, loss: 0.005286396015435457, accuracy: (0.99843752, 0.99844235)\n",
      "step: 321, loss: 0.005250945687294006, accuracy: (0.99844235, 0.99844718)\n",
      "step: 322, loss: 0.005214037373661995, accuracy: (0.99844718, 0.99845201)\n",
      "step: 323, loss: 0.005178199149668217, accuracy: (0.99845201, 0.99845678)\n",
      "step: 324, loss: 0.0051433793269097805, accuracy: (0.99845678, 0.99846154)\n",
      "step: 325, loss: 0.005108957644551992, accuracy: (0.99846154, 0.99846625)\n",
      "step: 326, loss: 0.005075213965028524, accuracy: (0.99846625, 0.99847096)\n",
      "step: 327, loss: 0.005041199270635843, accuracy: (0.99847096, 0.99847561)\n",
      "step: 328, loss: 0.0050069536082446575, accuracy: (0.99847561, 0.99848026)\n",
      "step: 329, loss: 0.004973333794623613, accuracy: (0.99848026, 0.99848485)\n",
      "step: 330, loss: 0.004940819926559925, accuracy: (0.99848485, 0.99848944)\n",
      "step: 331, loss: 0.0049077607691287994, accuracy: (0.99848944, 0.99849397)\n",
      "step: 332, loss: 0.004876032471656799, accuracy: (0.99849397, 0.9984985)\n",
      "step: 333, loss: 0.004845231771469116, accuracy: (0.9984985, 0.99850297)\n",
      "step: 334, loss: 0.0048132105730473995, accuracy: (0.99850297, 0.99850744)\n",
      "step: 335, loss: 0.004781929310411215, accuracy: (0.99850744, 0.99851191)\n",
      "step: 336, loss: 0.004751565866172314, accuracy: (0.99851191, 0.99851632)\n",
      "step: 337, loss: 0.004720653407275677, accuracy: (0.99851632, 0.99852073)\n",
      "step: 338, loss: 0.004690538160502911, accuracy: (0.99852073, 0.99852508)\n",
      "step: 339, loss: 0.004662135150283575, accuracy: (0.99852508, 0.99852943)\n",
      "step: 340, loss: 0.004631749354302883, accuracy: (0.99852943, 0.99853373)\n",
      "step: 341, loss: 0.004602261818945408, accuracy: (0.99853373, 0.99853802)\n",
      "step: 342, loss: 0.004574444144964218, accuracy: (0.99853802, 0.99854225)\n",
      "step: 343, loss: 0.004545627627521753, accuracy: (0.99854225, 0.99854654)\n",
      "step: 344, loss: 0.004517069086432457, accuracy: (0.99854654, 0.99855071)\n",
      "step: 345, loss: 0.004489884711802006, accuracy: (0.99855071, 0.99855489)\n",
      "step: 346, loss: 0.004462612327188253, accuracy: (0.99855489, 0.99855906)\n",
      "step: 347, loss: 0.004434647038578987, accuracy: (0.99855906, 0.99856323)\n",
      "step: 348, loss: 0.0044080764055252075, accuracy: (0.99856323, 0.99856734)\n",
      "step: 349, loss: 0.004380958620458841, accuracy: (0.99856734, 0.99857146)\n",
      "step: 350, loss: 0.004354478325694799, accuracy: (0.99857146, 0.99857551)\n",
      "step: 351, loss: 0.00432923436164856, accuracy: (0.99857551, 0.99857956)\n",
      "step: 352, loss: 0.004303155466914177, accuracy: (0.99857956, 0.99858356)\n",
      "step: 353, loss: 0.004277101717889309, accuracy: (0.99858356, 0.99858755)\n",
      "step: 354, loss: 0.004251853562891483, accuracy: (0.99858755, 0.99859154)\n",
      "step: 355, loss: 0.0042268517427146435, accuracy: (0.99859154, 0.99859548)\n",
      "step: 356, loss: 0.0042016166262328625, accuracy: (0.99859548, 0.99859941)\n",
      "step: 357, loss: 0.004177594557404518, accuracy: (0.99859941, 0.99860334)\n",
      "step: 358, loss: 0.00415332056581974, accuracy: (0.99860334, 0.99860722)\n",
      "step: 359, loss: 0.004128769971430302, accuracy: (0.99860722, 0.99861109)\n",
      "step: 360, loss: 0.00410502590239048, accuracy: (0.99861109, 0.99861497)\n",
      "step: 361, loss: 0.0040813228115439415, accuracy: (0.99861497, 0.99861878)\n",
      "step: 362, loss: 0.004058104008436203, accuracy: (0.99861878, 0.9986226)\n",
      "step: 363, loss: 0.004035642370581627, accuracy: (0.9986226, 0.99862635)\n",
      "step: 364, loss: 0.004012575373053551, accuracy: (0.99862635, 0.99863017)\n",
      "step: 365, loss: 0.0039892857894301414, accuracy: (0.99863017, 0.99863386)\n",
      "step: 366, loss: 0.003966705873608589, accuracy: (0.99863386, 0.99863762)\n",
      "step: 367, loss: 0.003944601397961378, accuracy: (0.99863762, 0.99864131)\n",
      "step: 368, loss: 0.003922460600733757, accuracy: (0.99864131, 0.99864501)\n",
      "step: 369, loss: 0.003900555893778801, accuracy: (0.99864501, 0.99864864)\n",
      "step: 370, loss: 0.003879423486068845, accuracy: (0.99864864, 0.99865228)\n",
      "step: 371, loss: 0.003857603296637535, accuracy: (0.99865228, 0.99865592)\n",
      "step: 372, loss: 0.003836271120235324, accuracy: (0.99865592, 0.99865949)\n",
      "step: 373, loss: 0.0038154430221766233, accuracy: (0.99865949, 0.99866313)\n",
      "step: 374, loss: 0.003794342279434204, accuracy: (0.99866313, 0.99866664)\n",
      "step: 375, loss: 0.0037738687824457884, accuracy: (0.99866664, 0.99867022)\n",
      "step: 376, loss: 0.0037536609452217817, accuracy: (0.99867022, 0.99867374)\n",
      "step: 377, loss: 0.003733409568667412, accuracy: (0.99867374, 0.99867725)\n",
      "step: 378, loss: 0.003713259007781744, accuracy: (0.99867725, 0.99868071)\n",
      "step: 379, loss: 0.003693602280691266, accuracy: (0.99868071, 0.99868423)\n",
      "step: 380, loss: 0.0036736882757395506, accuracy: (0.99868423, 0.99868768)\n",
      "step: 381, loss: 0.003653954016044736, accuracy: (0.99868768, 0.99869108)\n",
      "step: 382, loss: 0.0036347652785480022, accuracy: (0.99869108, 0.99869454)\n",
      "step: 383, loss: 0.003615899011492729, accuracy: (0.99869454, 0.99869794)\n",
      "step: 384, loss: 0.0035966329742223024, accuracy: (0.99869794, 0.99870127)\n",
      "step: 385, loss: 0.00357801397331059, accuracy: (0.99870127, 0.99870467)\n",
      "step: 386, loss: 0.003559271339327097, accuracy: (0.99870467, 0.99870801)\n",
      "step: 387, loss: 0.003540532663464546, accuracy: (0.99870801, 0.99871135)\n",
      "step: 388, loss: 0.0035225674510002136, accuracy: (0.99871135, 0.99871463)\n",
      "step: 389, loss: 0.0035045191179960966, accuracy: (0.99871463, 0.99871796)\n",
      "step: 390, loss: 0.0034863618202507496, accuracy: (0.99871796, 0.99872124)\n",
      "step: 391, loss: 0.0034686806611716747, accuracy: (0.99872124, 0.99872446)\n",
      "step: 392, loss: 0.0034511766862124205, accuracy: (0.99872446, 0.99872774)\n",
      "step: 393, loss: 0.0034334927331656218, accuracy: (0.99872774, 0.99873096)\n",
      "step: 394, loss: 0.003415919141843915, accuracy: (0.99873096, 0.99873418)\n",
      "step: 395, loss: 0.003398951841518283, accuracy: (0.99873418, 0.99873739)\n",
      "step: 396, loss: 0.003381711896508932, accuracy: (0.99873739, 0.99874055)\n",
      "step: 397, loss: 0.0033650591503828764, accuracy: (0.99874055, 0.99874371)\n",
      "step: 398, loss: 0.003348377998918295, accuracy: (0.99874371, 0.99874687)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 399, loss: 0.003331600222736597, accuracy: (0.99874687, 0.99874997)\n",
      "step: 400, loss: 0.003314834786579013, accuracy: (0.99874997, 0.99875313)\n",
      "step: 401, loss: 0.0032988216262310743, accuracy: (0.99875313, 0.99875623)\n",
      "step: 402, loss: 0.0032828482799232006, accuracy: (0.99875623, 0.99875933)\n",
      "step: 403, loss: 0.0032663592137396336, accuracy: (0.99875933, 0.99876237)\n",
      "step: 404, loss: 0.0032505206763744354, accuracy: (0.99876237, 0.99876541)\n",
      "step: 405, loss: 0.0032350807450711727, accuracy: (0.99876541, 0.99876845)\n",
      "step: 406, loss: 0.003219176549464464, accuracy: (0.99876845, 0.99877149)\n",
      "step: 407, loss: 0.003203627187758684, accuracy: (0.99877149, 0.99877453)\n",
      "step: 408, loss: 0.003188247326761484, accuracy: (0.99877453, 0.99877751)\n",
      "step: 409, loss: 0.003172872122377157, accuracy: (0.99877751, 0.99878049)\n",
      "step: 410, loss: 0.003157957922667265, accuracy: (0.99878049, 0.99878347)\n",
      "step: 411, loss: 0.0031431373208761215, accuracy: (0.99878347, 0.99878639)\n",
      "step: 412, loss: 0.0031279935501515865, accuracy: (0.99878639, 0.99878937)\n",
      "step: 413, loss: 0.003113170387223363, accuracy: (0.99878937, 0.99879229)\n",
      "step: 414, loss: 0.003098574001342058, accuracy: (0.99879229, 0.99879515)\n",
      "step: 415, loss: 0.0030839587561786175, accuracy: (0.99879515, 0.99879807)\n",
      "step: 416, loss: 0.003069669008255005, accuracy: (0.99879807, 0.99880093)\n",
      "step: 417, loss: 0.0030558970756828785, accuracy: (0.99880093, 0.99880385)\n",
      "step: 418, loss: 0.003041285090148449, accuracy: (0.99880385, 0.99880666)\n",
      "step: 419, loss: 0.0030270495917648077, accuracy: (0.99880666, 0.99880952)\n",
      "step: 420, loss: 0.003013437148183584, accuracy: (0.99880952, 0.99881238)\n",
      "step: 421, loss: 0.002999331336468458, accuracy: (0.99881238, 0.99881518)\n",
      "step: 422, loss: 0.002985402476042509, accuracy: (0.99881518, 0.99881798)\n",
      "step: 423, loss: 0.0029718512669205666, accuracy: (0.99881798, 0.99882078)\n",
      "step: 424, loss: 0.0029586181044578552, accuracy: (0.99882078, 0.99882352)\n",
      "step: 425, loss: 0.002945131855085492, accuracy: (0.99882352, 0.99882627)\n",
      "step: 426, loss: 0.002931833267211914, accuracy: (0.99882627, 0.99882907)\n",
      "step: 427, loss: 0.0029186191968619823, accuracy: (0.99882907, 0.99883175)\n",
      "step: 428, loss: 0.0029053667094558477, accuracy: (0.99883175, 0.99883449)\n",
      "step: 429, loss: 0.0028924166690558195, accuracy: (0.99883449, 0.99883723)\n",
      "step: 430, loss: 0.002879585139453411, accuracy: (0.99883723, 0.99883991)\n",
      "step: 431, loss: 0.0028667734004557133, accuracy: (0.99883991, 0.9988426)\n",
      "step: 432, loss: 0.002854146296158433, accuracy: (0.9988426, 0.99884528)\n",
      "step: 433, loss: 0.002841597655788064, accuracy: (0.99884528, 0.9988479)\n",
      "step: 434, loss: 0.002829001983627677, accuracy: (0.9988479, 0.99885058)\n",
      "step: 435, loss: 0.002816448686644435, accuracy: (0.99885058, 0.99885321)\n",
      "step: 436, loss: 0.0028042790945619345, accuracy: (0.99885321, 0.99885583)\n",
      "step: 437, loss: 0.002791977021843195, accuracy: (0.99885583, 0.99885845)\n",
      "step: 438, loss: 0.002780002076178789, accuracy: (0.99885845, 0.99886107)\n",
      "step: 439, loss: 0.002768109319731593, accuracy: (0.99886107, 0.99886364)\n",
      "step: 440, loss: 0.0027561706956475973, accuracy: (0.9988662, 0.9988662)\n",
      "step: 441, loss: 0.0027441484853625298, accuracy: (0.9988662, 0.99886876)\n",
      "step: 442, loss: 0.002732269000262022, accuracy: (0.99886876, 0.99887133)\n",
      "step: 443, loss: 0.0027207781095057726, accuracy: (0.99887133, 0.99887389)\n",
      "step: 444, loss: 0.002709074877202511, accuracy: (0.99887389, 0.99887639)\n",
      "step: 445, loss: 0.002697435673326254, accuracy: (0.99887639, 0.9988789)\n",
      "step: 446, loss: 0.002686301013454795, accuracy: (0.9988789, 0.99888146)\n",
      "step: 447, loss: 0.002675131428986788, accuracy: (0.99888146, 0.9988839)\n",
      "step: 448, loss: 0.0026635373942553997, accuracy: (0.9988839, 0.99888641)\n",
      "step: 449, loss: 0.0026525233406573534, accuracy: (0.99888641, 0.99888891)\n",
      "step: 450, loss: 0.0026413665618747473, accuracy: (0.99888891, 0.99889135)\n",
      "step: 451, loss: 0.0026302121113985777, accuracy: (0.99889135, 0.9988938)\n",
      "step: 452, loss: 0.0026192553341388702, accuracy: (0.9988938, 0.99889624)\n",
      "step: 453, loss: 0.002608667593449354, accuracy: (0.99889624, 0.99889868)\n",
      "step: 454, loss: 0.002597830491140485, accuracy: (0.99889868, 0.99890107)\n",
      "step: 455, loss: 0.0025869908276945353, accuracy: (0.99890107, 0.99890351)\n",
      "step: 456, loss: 0.00257651275023818, accuracy: (0.99890351, 0.9989059)\n",
      "step: 457, loss: 0.002565887523815036, accuracy: (0.9989059, 0.99890828)\n",
      "step: 458, loss: 0.0025554143358021975, accuracy: (0.99890828, 0.99891067)\n",
      "step: 459, loss: 0.002545268042013049, accuracy: (0.99891067, 0.99891305)\n",
      "step: 460, loss: 0.0025348858907818794, accuracy: (0.99891305, 0.99891537)\n",
      "step: 461, loss: 0.0025244983844459057, accuracy: (0.99891537, 0.99891776)\n",
      "step: 462, loss: 0.002514287829399109, accuracy: (0.99891776, 0.99892008)\n",
      "step: 463, loss: 0.0025042605120688677, accuracy: (0.99892008, 0.99892241)\n",
      "step: 464, loss: 0.002494099782779813, accuracy: (0.99892241, 0.99892473)\n",
      "step: 465, loss: 0.0024841721169650555, accuracy: (0.99892473, 0.99892706)\n",
      "step: 466, loss: 0.0024745455011725426, accuracy: (0.99892706, 0.99892932)\n",
      "step: 467, loss: 0.0024644467048346996, accuracy: (0.99892932, 0.99893165)\n",
      "step: 468, loss: 0.0024546796921640635, accuracy: (0.99893165, 0.99893391)\n",
      "step: 469, loss: 0.0024452591314911842, accuracy: (0.99893391, 0.99893618)\n",
      "step: 470, loss: 0.002435569651424885, accuracy: (0.99893618, 0.99893844)\n",
      "step: 471, loss: 0.0024258908815681934, accuracy: (0.99893844, 0.99894071)\n",
      "step: 472, loss: 0.00241639232262969, accuracy: (0.99894071, 0.99894291)\n",
      "step: 473, loss: 0.0024070178624242544, accuracy: (0.99894291, 0.99894518)\n",
      "step: 474, loss: 0.0023975432850420475, accuracy: (0.99894518, 0.99894738)\n",
      "step: 475, loss: 0.0023882235400378704, accuracy: (0.99894738, 0.99894959)\n",
      "step: 476, loss: 0.002379306824877858, accuracy: (0.99894959, 0.99895179)\n",
      "step: 477, loss: 0.0023699377197772264, accuracy: (0.99895179, 0.998954)\n",
      "step: 478, loss: 0.0023607490584254265, accuracy: (0.998954, 0.99895614)\n",
      "step: 479, loss: 0.0023517892695963383, accuracy: (0.99895614, 0.99895835)\n",
      "step: 480, loss: 0.0023427405394613743, accuracy: (0.99895835, 0.99896049)\n",
      "step: 481, loss: 0.0023337649181485176, accuracy: (0.99896049, 0.99896264)\n",
      "step: 482, loss: 0.0023250237572938204, accuracy: (0.99896264, 0.99896479)\n",
      "step: 483, loss: 0.0023162856232374907, accuracy: (0.99896479, 0.99896693)\n",
      "step: 484, loss: 0.00230741361156106, accuracy: (0.99896693, 0.99896908)\n",
      "step: 485, loss: 0.0022986356634646654, accuracy: (0.99896908, 0.99897116)\n",
      "step: 486, loss: 0.00229006540030241, accuracy: (0.99897116, 0.99897331)\n",
      "step: 487, loss: 0.0022814564872533083, accuracy: (0.99897331, 0.9989754)\n",
      "step: 488, loss: 0.002272865502163768, accuracy: (0.9989754, 0.99897748)\n",
      "step: 489, loss: 0.002264604903757572, accuracy: (0.99897748, 0.99897957)\n",
      "step: 490, loss: 0.002256107283756137, accuracy: (0.99897957, 0.99898165)\n",
      "step: 491, loss: 0.0022476338781416416, accuracy: (0.99898165, 0.99898374)\n",
      "step: 492, loss: 0.0022393683902919292, accuracy: (0.99898374, 0.99898583)\n",
      "step: 493, loss: 0.002231240039691329, accuracy: (0.99898583, 0.99898785)\n",
      "step: 494, loss: 0.0022228837478905916, accuracy: (0.99898785, 0.99898988)\n",
      "step: 495, loss: 0.002214710460975766, accuracy: (0.99898988, 0.99899191)\n",
      "step: 496, loss: 0.002206717152148485, accuracy: (0.99899191, 0.99899399)\n",
      "step: 497, loss: 0.00219870381988585, accuracy: (0.99899399, 0.99899596)\n",
      "step: 498, loss: 0.002190606901422143, accuracy: (0.99899596, 0.99899799)\n",
      "step: 499, loss: 0.0021827679593116045, accuracy: (0.99899799, 0.99900001)\n",
      "step: 500, loss: 0.0021748431026935577, accuracy: (0.99900001, 0.99900198)\n",
      "step: 501, loss: 0.0021669657435268164, accuracy: (0.99900198, 0.99900401)\n",
      "step: 502, loss: 0.002159157767891884, accuracy: (0.99900401, 0.99900597)\n",
      "step: 503, loss: 0.0021514776162803173, accuracy: (0.99900597, 0.99900794)\n",
      "step: 504, loss: 0.0021437383256852627, accuracy: (0.99900794, 0.99900991)\n",
      "step: 505, loss: 0.002135991118848324, accuracy: (0.99900991, 0.99901187)\n",
      "step: 506, loss: 0.002128533786162734, accuracy: (0.99901187, 0.99901378)\n",
      "step: 507, loss: 0.002121038269251585, accuracy: (0.99901378, 0.99901575)\n",
      "step: 508, loss: 0.0021134139969944954, accuracy: (0.99901575, 0.99901766)\n",
      "step: 509, loss: 0.0021060022991150618, accuracy: (0.99901766, 0.99901962)\n",
      "step: 510, loss: 0.002098635770380497, accuracy: (0.99901962, 0.99902153)\n",
      "step: 511, loss: 0.0020911479368805885, accuracy: (0.99902153, 0.99902344)\n",
      "step: 512, loss: 0.0020837662741541862, accuracy: (0.99902344, 0.99902534)\n",
      "step: 513, loss: 0.0020767441019415855, accuracy: (0.99902534, 0.99902725)\n",
      "step: 514, loss: 0.0020694020204246044, accuracy: (0.99902725, 0.9990291)\n",
      "step: 515, loss: 0.002061802428215742, accuracy: (0.9990291, 0.99903101)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 516, loss: 0.002054415876045823, accuracy: (0.99903101, 0.99903286)\n",
      "step: 517, loss: 0.002047180198132992, accuracy: (0.99903286, 0.99903476)\n",
      "step: 518, loss: 0.0020397836342453957, accuracy: (0.99903476, 0.99903661)\n",
      "step: 519, loss: 0.002032497199252248, accuracy: (0.99903661, 0.99903846)\n",
      "step: 520, loss: 0.00202557654120028, accuracy: (0.99903846, 0.99904031)\n",
      "step: 521, loss: 0.002018161118030548, accuracy: (0.99904031, 0.99904215)\n",
      "step: 522, loss: 0.0020110360346734524, accuracy: (0.99904215, 0.999044)\n",
      "step: 523, loss: 0.002004035050049424, accuracy: (0.999044, 0.99904579)\n",
      "step: 524, loss: 0.001996970269829035, accuracy: (0.99904579, 0.99904764)\n",
      "step: 525, loss: 0.0019901501946151257, accuracy: (0.99904764, 0.99904943)\n",
      "step: 526, loss: 0.0019829869270324707, accuracy: (0.99904943, 0.99905121)\n",
      "step: 527, loss: 0.0019760860595852137, accuracy: (0.99905121, 0.999053)\n",
      "step: 528, loss: 0.0019693798385560513, accuracy: (0.999053, 0.99905485)\n",
      "step: 529, loss: 0.001962409820407629, accuracy: (0.99905485, 0.99905658)\n",
      "step: 530, loss: 0.001955683110281825, accuracy: (0.99905658, 0.99905837)\n",
      "step: 531, loss: 0.0019491424318403006, accuracy: (0.99905837, 0.99906015)\n",
      "step: 532, loss: 0.0019421946490183473, accuracy: (0.99906015, 0.99906194)\n",
      "step: 533, loss: 0.0019357356941327453, accuracy: (0.99906194, 0.99906367)\n",
      "step: 534, loss: 0.0019289609044790268, accuracy: (0.99906367, 0.9990654)\n",
      "step: 535, loss: 0.0019224981078878045, accuracy: (0.9990654, 0.99906719)\n",
      "step: 536, loss: 0.0019159631337970495, accuracy: (0.99906719, 0.99906892)\n",
      "step: 537, loss: 0.0019092917209491134, accuracy: (0.99906892, 0.99907064)\n",
      "step: 538, loss: 0.0019030061084777117, accuracy: (0.99907064, 0.99907237)\n",
      "step: 539, loss: 0.001896643778309226, accuracy: (0.99907237, 0.9990741)\n",
      "step: 540, loss: 0.0018900306895375252, accuracy: (0.9990741, 0.99907577)\n",
      "step: 541, loss: 0.0018838115502148867, accuracy: (0.99907577, 0.9990775)\n",
      "step: 542, loss: 0.0018774870550259948, accuracy: (0.9990775, 0.99907917)\n",
      "step: 543, loss: 0.0018712051678448915, accuracy: (0.99907917, 0.9990809)\n",
      "step: 544, loss: 0.001865053316578269, accuracy: (0.9990809, 0.99908257)\n",
      "step: 545, loss: 0.0018587096128612757, accuracy: (0.99908257, 0.99908423)\n",
      "step: 546, loss: 0.0018526822095736861, accuracy: (0.99908423, 0.9990859)\n",
      "step: 547, loss: 0.0018464777385815978, accuracy: (0.9990859, 0.99908757)\n",
      "step: 548, loss: 0.0018403192516416311, accuracy: (0.99908757, 0.99908924)\n",
      "step: 549, loss: 0.0018344760173931718, accuracy: (0.99908924, 0.99909091)\n",
      "step: 550, loss: 0.0018282958772033453, accuracy: (0.99909091, 0.99909258)\n",
      "step: 551, loss: 0.0018223824445158243, accuracy: (0.99909258, 0.99909419)\n",
      "step: 552, loss: 0.001816359581425786, accuracy: (0.99909419, 0.99909586)\n",
      "step: 553, loss: 0.001810468384064734, accuracy: (0.99909586, 0.99909747)\n",
      "step: 554, loss: 0.001804669969715178, accuracy: (0.99909747, 0.99909908)\n",
      "step: 555, loss: 0.0017986949533224106, accuracy: (0.99909908, 0.99910074)\n",
      "step: 556, loss: 0.0017928571905940771, accuracy: (0.99910074, 0.99910235)\n",
      "step: 557, loss: 0.0017872846219688654, accuracy: (0.99910235, 0.99910396)\n",
      "step: 558, loss: 0.0017813192680478096, accuracy: (0.99910396, 0.99910557)\n",
      "step: 559, loss: 0.0017755985027179122, accuracy: (0.99910557, 0.99910712)\n",
      "step: 560, loss: 0.0017700372263789177, accuracy: (0.99910712, 0.99910873)\n",
      "step: 561, loss: 0.0017642609309405088, accuracy: (0.99910873, 0.99911034)\n",
      "step: 562, loss: 0.001758677652105689, accuracy: (0.99911034, 0.99911189)\n",
      "step: 563, loss: 0.0017530873883515596, accuracy: (0.99911189, 0.9991135)\n",
      "step: 564, loss: 0.0017475590575486422, accuracy: (0.9991135, 0.99911505)\n",
      "step: 565, loss: 0.0017420798540115356, accuracy: (0.99911505, 0.9991166)\n",
      "step: 566, loss: 0.0017364289378747344, accuracy: (0.9991166, 0.99911815)\n",
      "step: 567, loss: 0.0017309983959421515, accuracy: (0.99911815, 0.9991197)\n",
      "step: 568, loss: 0.0017257386352866888, accuracy: (0.9991197, 0.99912125)\n",
      "step: 569, loss: 0.0017201278824359179, accuracy: (0.99912125, 0.9991228)\n",
      "step: 570, loss: 0.001714853337034583, accuracy: (0.9991228, 0.99912435)\n",
      "step: 571, loss: 0.001709457254037261, accuracy: (0.99912435, 0.9991259)\n",
      "step: 572, loss: 0.0017041394021362066, accuracy: (0.9991259, 0.99912739)\n",
      "step: 573, loss: 0.001698898384347558, accuracy: (0.99912739, 0.99912894)\n",
      "step: 574, loss: 0.0016936033498495817, accuracy: (0.99912894, 0.99913043)\n",
      "step: 575, loss: 0.0016885565128177404, accuracy: (0.99913043, 0.99913192)\n",
      "step: 576, loss: 0.0016832745168358088, accuracy: (0.99913192, 0.99913347)\n",
      "step: 577, loss: 0.0016781624872237444, accuracy: (0.99913347, 0.99913496)\n",
      "step: 578, loss: 0.0016730267088860273, accuracy: (0.99913496, 0.99913645)\n",
      "step: 579, loss: 0.0016680428525432944, accuracy: (0.99913645, 0.99913794)\n",
      "step: 580, loss: 0.0016629040474072099, accuracy: (0.99913794, 0.99913943)\n",
      "step: 581, loss: 0.0016578339273110032, accuracy: (0.99913943, 0.99914092)\n",
      "step: 582, loss: 0.0016528929118067026, accuracy: (0.99914092, 0.99914235)\n",
      "step: 583, loss: 0.0016480199992656708, accuracy: (0.99914235, 0.99914384)\n",
      "step: 584, loss: 0.0016429182142019272, accuracy: (0.99914384, 0.99914527)\n",
      "step: 585, loss: 0.0016380615998059511, accuracy: (0.99914527, 0.99914676)\n",
      "step: 586, loss: 0.0016331750666722655, accuracy: (0.99914676, 0.99914819)\n",
      "step: 587, loss: 0.0016284175217151642, accuracy: (0.99914819, 0.99914968)\n",
      "step: 588, loss: 0.0016233347123488784, accuracy: (0.99914968, 0.99915111)\n",
      "step: 589, loss: 0.0016187233850359917, accuracy: (0.99915111, 0.99915254)\n",
      "step: 590, loss: 0.0016138609498739243, accuracy: (0.99915254, 0.99915397)\n",
      "step: 591, loss: 0.001609042868949473, accuracy: (0.99915397, 0.9991554)\n",
      "step: 592, loss: 0.0016043779905885458, accuracy: (0.9991554, 0.99915683)\n",
      "step: 593, loss: 0.0015995915746316314, accuracy: (0.99915683, 0.99915826)\n",
      "step: 594, loss: 0.0015950422966852784, accuracy: (0.99915826, 0.99915963)\n",
      "step: 595, loss: 0.0015901755541563034, accuracy: (0.99915963, 0.99916106)\n",
      "step: 596, loss: 0.0015856543323025107, accuracy: (0.99916106, 0.9991625)\n",
      "step: 597, loss: 0.0015809498727321625, accuracy: (0.9991625, 0.99916387)\n",
      "step: 598, loss: 0.0015763600822538137, accuracy: (0.99916387, 0.9991653)\n",
      "step: 599, loss: 0.0015718468930572271, accuracy: (0.9991653, 0.99916667)\n",
      "step: 600, loss: 0.0015672100707888603, accuracy: (0.99916667, 0.99916804)\n",
      "step: 601, loss: 0.001562686637043953, accuracy: (0.99916804, 0.99916941)\n",
      "step: 602, loss: 0.0015584524953737855, accuracy: (0.99916941, 0.99917084)\n",
      "step: 603, loss: 0.0015539866872131824, accuracy: (0.99917084, 0.99917221)\n",
      "step: 604, loss: 0.0015493377577513456, accuracy: (0.99917221, 0.99917358)\n",
      "step: 605, loss: 0.0015448837075382471, accuracy: (0.99917358, 0.99917489)\n",
      "step: 606, loss: 0.0015405479352921247, accuracy: (0.99917489, 0.99917626)\n",
      "step: 607, loss: 0.0015360338147729635, accuracy: (0.99917626, 0.99917763)\n",
      "step: 608, loss: 0.001531859626993537, accuracy: (0.99917763, 0.99917901)\n",
      "step: 609, loss: 0.00152736552990973, accuracy: (0.99917901, 0.99918032)\n",
      "step: 610, loss: 0.001523202401585877, accuracy: (0.99918032, 0.99918169)\n",
      "step: 611, loss: 0.001518829958513379, accuracy: (0.99918169, 0.999183)\n",
      "step: 612, loss: 0.0015145179349929094, accuracy: (0.999183, 0.99918431)\n",
      "step: 613, loss: 0.0015102771576493979, accuracy: (0.99918431, 0.99918568)\n",
      "step: 614, loss: 0.00150591682177037, accuracy: (0.99918568, 0.99918699)\n",
      "step: 615, loss: 0.0015019983984529972, accuracy: (0.99918699, 0.9991883)\n",
      "step: 616, loss: 0.0014978324761614203, accuracy: (0.9991883, 0.99918962)\n",
      "step: 617, loss: 0.0014934352366253734, accuracy: (0.99918962, 0.99919093)\n",
      "step: 618, loss: 0.0014892823528498411, accuracy: (0.99919093, 0.99919224)\n",
      "step: 619, loss: 0.0014852248132228851, accuracy: (0.99919224, 0.99919355)\n",
      "step: 620, loss: 0.0014809954445809126, accuracy: (0.99919355, 0.99919486)\n",
      "step: 621, loss: 0.001476953155361116, accuracy: (0.99919486, 0.99919611)\n",
      "step: 622, loss: 0.0014727769885212183, accuracy: (0.99919611, 0.99919742)\n",
      "step: 623, loss: 0.0014687447110190988, accuracy: (0.99919742, 0.99919873)\n",
      "step: 624, loss: 0.0014648445649072528, accuracy: (0.99919873, 0.99919999)\n",
      "step: 625, loss: 0.0014607375487685204, accuracy: (0.99919999, 0.9992013)\n",
      "step: 626, loss: 0.0014568250626325607, accuracy: (0.9992013, 0.99920255)\n",
      "step: 627, loss: 0.0014527931343764067, accuracy: (0.99920255, 0.9992038)\n",
      "step: 628, loss: 0.0014488304732367396, accuracy: (0.9992038, 0.99920511)\n",
      "step: 629, loss: 0.0014448945876210928, accuracy: (0.99920511, 0.99920636)\n",
      "step: 630, loss: 0.0014409245923161507, accuracy: (0.99920636, 0.99920762)\n",
      "step: 631, loss: 0.0014371706638485193, accuracy: (0.99920762, 0.99920887)\n",
      "step: 632, loss: 0.0014331031125038862, accuracy: (0.99920887, 0.99921012)\n",
      "step: 633, loss: 0.0014294669963419437, accuracy: (0.99921012, 0.99921137)\n",
      "step: 634, loss: 0.0014254578854888678, accuracy: (0.99921137, 0.99921262)\n",
      "step: 635, loss: 0.0014217402786016464, accuracy: (0.99921262, 0.99921381)\n",
      "step: 636, loss: 0.0014180231373757124, accuracy: (0.99921381, 0.99921507)\n",
      "step: 637, loss: 0.0014140958664938807, accuracy: (0.99921507, 0.99921632)\n",
      "step: 638, loss: 0.001410310622304678, accuracy: (0.99921632, 0.99921751)\n",
      "step: 639, loss: 0.001406591385602951, accuracy: (0.99921751, 0.99921876)\n",
      "step: 640, loss: 0.001402794267050922, accuracy: (0.99921876, 0.99921995)\n",
      "step: 641, loss: 0.0013991770101711154, accuracy: (0.99921995, 0.99922121)\n",
      "step: 642, loss: 0.0013953088782727718, accuracy: (0.99922121, 0.9992224)\n",
      "step: 643, loss: 0.0013917317846789956, accuracy: (0.9992224, 0.99922359)\n",
      "step: 644, loss: 0.0013879805337637663, accuracy: (0.99922359, 0.99922478)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 645, loss: 0.001384599832817912, accuracy: (0.99922478, 0.99922603)\n",
      "step: 646, loss: 0.0013808622024953365, accuracy: (0.99922603, 0.99922723)\n",
      "step: 647, loss: 0.0013771142112091184, accuracy: (0.99922723, 0.99922842)\n",
      "step: 648, loss: 0.0013735650572925806, accuracy: (0.99922842, 0.99922961)\n",
      "step: 649, loss: 0.0013699521077796817, accuracy: (0.99922961, 0.99923074)\n",
      "step: 650, loss: 0.001366353128105402, accuracy: (0.99923074, 0.99923193)\n",
      "step: 651, loss: 0.0013628308661282063, accuracy: (0.99923193, 0.99923313)\n",
      "step: 652, loss: 0.0013592314207926393, accuracy: (0.99923313, 0.99923432)\n",
      "step: 653, loss: 0.0013558685313910246, accuracy: (0.99923432, 0.99923545)\n",
      "step: 654, loss: 0.0013521516229957342, accuracy: (0.99923545, 0.99923664)\n",
      "step: 655, loss: 0.0013488915283232927, accuracy: (0.99923664, 0.99923778)\n",
      "step: 656, loss: 0.00134532549418509, accuracy: (0.99923778, 0.99923897)\n",
      "step: 657, loss: 0.001341816270723939, accuracy: (0.99923897, 0.9992401)\n",
      "step: 658, loss: 0.0013384290505200624, accuracy: (0.9992401, 0.99924129)\n",
      "step: 659, loss: 0.0013350105145946145, accuracy: (0.99924129, 0.99924242)\n",
      "step: 660, loss: 0.0013317120028659701, accuracy: (0.99924242, 0.99924356)\n",
      "step: 661, loss: 0.0013281835708767176, accuracy: (0.99924356, 0.99924469)\n",
      "step: 662, loss: 0.0013248284813016653, accuracy: (0.99924469, 0.99924582)\n",
      "step: 663, loss: 0.0013215006329119205, accuracy: (0.99924582, 0.99924701)\n",
      "step: 664, loss: 0.0013180337846279144, accuracy: (0.99924701, 0.99924815)\n",
      "step: 665, loss: 0.0013148202560842037, accuracy: (0.99924815, 0.99924922)\n",
      "step: 666, loss: 0.0013114127796143293, accuracy: (0.99924922, 0.99925035)\n",
      "step: 667, loss: 0.0013082490768283606, accuracy: (0.99925035, 0.99925148)\n",
      "step: 668, loss: 0.0013050222769379616, accuracy: (0.99925148, 0.99925262)\n",
      "step: 669, loss: 0.00130160350818187, accuracy: (0.99925262, 0.99925375)\n",
      "step: 670, loss: 0.0012983186170458794, accuracy: (0.99925375, 0.99925482)\n",
      "step: 671, loss: 0.0012951580574736, accuracy: (0.99925482, 0.99925596)\n",
      "step: 672, loss: 0.0012917584972456098, accuracy: (0.99925596, 0.99925709)\n",
      "step: 673, loss: 0.0012886673212051392, accuracy: (0.99925709, 0.99925816)\n",
      "step: 674, loss: 0.001285399543121457, accuracy: (0.99925816, 0.99925923)\n",
      "step: 675, loss: 0.0012824165169149637, accuracy: (0.99925923, 0.99926037)\n",
      "step: 676, loss: 0.0012791838962584734, accuracy: (0.99926037, 0.99926144)\n",
      "step: 677, loss: 0.0012759154196828604, accuracy: (0.99926144, 0.99926251)\n",
      "step: 678, loss: 0.0012727517168968916, accuracy: (0.99926251, 0.99926364)\n",
      "step: 679, loss: 0.0012696462217718363, accuracy: (0.99926364, 0.99926472)\n",
      "step: 680, loss: 0.00126644445117563, accuracy: (0.99926472, 0.99926579)\n",
      "step: 681, loss: 0.001263438374735415, accuracy: (0.99926579, 0.99926686)\n",
      "step: 682, loss: 0.001260264776647091, accuracy: (0.99926686, 0.99926794)\n",
      "step: 683, loss: 0.00125724112149328, accuracy: (0.99926794, 0.99926901)\n",
      "step: 684, loss: 0.0012541500618681312, accuracy: (0.99926901, 0.99927008)\n",
      "step: 685, loss: 0.0012511310633271933, accuracy: (0.99927008, 0.99927115)\n",
      "step: 686, loss: 0.0012480317382141948, accuracy: (0.99927115, 0.99927223)\n",
      "step: 687, loss: 0.0012450497597455978, accuracy: (0.99927223, 0.99927324)\n",
      "step: 688, loss: 0.0012422236613929272, accuracy: (0.99927324, 0.99927431)\n",
      "step: 689, loss: 0.0012390732299536467, accuracy: (0.99927431, 0.99927539)\n",
      "step: 690, loss: 0.001235996256582439, accuracy: (0.99927539, 0.9992764)\n",
      "step: 691, loss: 0.0012329841265454888, accuracy: (0.9992764, 0.99927747)\n",
      "step: 692, loss: 0.0012301530223339796, accuracy: (0.99927747, 0.99927849)\n",
      "step: 693, loss: 0.0012271911837160587, accuracy: (0.99927849, 0.99927956)\n",
      "step: 694, loss: 0.001224190229550004, accuracy: (0.99927956, 0.99928057)\n",
      "step: 695, loss: 0.0012214425951242447, accuracy: (0.99928057, 0.99928159)\n",
      "step: 696, loss: 0.0012184628285467625, accuracy: (0.99928159, 0.99928266)\n",
      "step: 697, loss: 0.0012154404539614916, accuracy: (0.99928266, 0.99928367)\n",
      "step: 698, loss: 0.0012125875800848007, accuracy: (0.99928367, 0.99928468)\n",
      "step: 699, loss: 0.001209724461659789, accuracy: (0.99928468, 0.9992857)\n",
      "step: 700, loss: 0.0012068888172507286, accuracy: (0.9992857, 0.99928671)\n",
      "step: 701, loss: 0.001203947584144771, accuracy: (0.99928671, 0.99928772)\n",
      "step: 702, loss: 0.001201194478198886, accuracy: (0.99928772, 0.99928874)\n",
      "step: 703, loss: 0.001198281766846776, accuracy: (0.99928874, 0.99928975)\n",
      "step: 704, loss: 0.0011956315720453858, accuracy: (0.99928975, 0.99929076)\n",
      "step: 705, loss: 0.001192840514704585, accuracy: (0.99929076, 0.99929178)\n",
      "step: 706, loss: 0.0011899152304977179, accuracy: (0.99929178, 0.99929279)\n",
      "step: 707, loss: 0.0011871438473463058, accuracy: (0.99929279, 0.9992938)\n",
      "step: 708, loss: 0.001184401917271316, accuracy: (0.9992938, 0.99929476)\n",
      "step: 709, loss: 0.0011815420584753156, accuracy: (0.99929476, 0.99929577)\n",
      "step: 710, loss: 0.0011789632262662053, accuracy: (0.99929577, 0.99929678)\n",
      "step: 711, loss: 0.0011762719368562102, accuracy: (0.99929678, 0.99929774)\n",
      "step: 712, loss: 0.0011734133586287498, accuracy: (0.99929774, 0.99929875)\n",
      "step: 713, loss: 0.0011706496588885784, accuracy: (0.99929875, 0.99929971)\n",
      "step: 714, loss: 0.0011680091265588999, accuracy: (0.99929971, 0.99930072)\n",
      "step: 715, loss: 0.0011652468238025904, accuracy: (0.99930072, 0.99930167)\n",
      "step: 716, loss: 0.0011626380728557706, accuracy: (0.99930167, 0.99930263)\n",
      "step: 717, loss: 0.0011598640121519566, accuracy: (0.99930263, 0.99930364)\n",
      "step: 718, loss: 0.0011573792435228825, accuracy: (0.99930364, 0.99930459)\n",
      "step: 719, loss: 0.0011547805042937398, accuracy: (0.99930459, 0.99930555)\n",
      "step: 720, loss: 0.0011520121479406953, accuracy: (0.99930555, 0.9993065)\n",
      "step: 721, loss: 0.00114931701682508, accuracy: (0.9993065, 0.99930745)\n",
      "step: 722, loss: 0.001146809896454215, accuracy: (0.99930745, 0.99930841)\n",
      "step: 723, loss: 0.0011440961388871074, accuracy: (0.99930841, 0.99930942)\n",
      "step: 724, loss: 0.0011415212647989392, accuracy: (0.99930942, 0.99931037)\n",
      "step: 725, loss: 0.0011389288119971752, accuracy: (0.99931037, 0.99931127)\n",
      "step: 726, loss: 0.0011364443926140666, accuracy: (0.99931127, 0.99931222)\n",
      "step: 727, loss: 0.0011337671894580126, accuracy: (0.99931222, 0.99931318)\n",
      "step: 728, loss: 0.0011313235154375434, accuracy: (0.99931318, 0.99931413)\n",
      "step: 729, loss: 0.001128694275394082, accuracy: (0.99931413, 0.99931508)\n",
      "step: 730, loss: 0.0011261742329224944, accuracy: (0.99931508, 0.99931598)\n",
      "step: 731, loss: 0.001123705878853798, accuracy: (0.99931598, 0.99931693)\n",
      "step: 732, loss: 0.0011210935190320015, accuracy: (0.99931693, 0.99931788)\n",
      "step: 733, loss: 0.0011188292410224676, accuracy: (0.99931788, 0.99931878)\n",
      "step: 734, loss: 0.0011162194423377514, accuracy: (0.99931878, 0.99931973)\n",
      "step: 735, loss: 0.0011136155808344483, accuracy: (0.99931973, 0.99932063)\n",
      "step: 736, loss: 0.0011112306965515018, accuracy: (0.99932063, 0.99932158)\n",
      "step: 737, loss: 0.0011087404564023018, accuracy: (0.99932158, 0.99932247)\n",
      "step: 738, loss: 0.0011062303092330694, accuracy: (0.99932247, 0.99932343)\n",
      "step: 739, loss: 0.001103872200474143, accuracy: (0.99932343, 0.99932432)\n",
      "step: 740, loss: 0.0011013459879904985, accuracy: (0.99932432, 0.99932522)\n",
      "step: 741, loss: 0.0010991869494318962, accuracy: (0.99932522, 0.99932617)\n",
      "step: 742, loss: 0.001096614869311452, accuracy: (0.99932617, 0.99932706)\n",
      "step: 743, loss: 0.001094095641747117, accuracy: (0.99932706, 0.99932796)\n",
      "step: 744, loss: 0.0010918043553829193, accuracy: (0.99932796, 0.99932885)\n",
      "step: 745, loss: 0.00108948047272861, accuracy: (0.99932885, 0.99932975)\n",
      "step: 746, loss: 0.0010870032710954547, accuracy: (0.99932975, 0.99933064)\n",
      "step: 747, loss: 0.0010845919605344534, accuracy: (0.99933064, 0.99933153)\n",
      "step: 748, loss: 0.0010822946205735207, accuracy: (0.99933153, 0.99933243)\n",
      "step: 749, loss: 0.0010798799339681864, accuracy: (0.99933243, 0.99933332)\n",
      "step: 750, loss: 0.0010776035487651825, accuracy: (0.99933332, 0.99933422)\n",
      "step: 751, loss: 0.0010751690715551376, accuracy: (0.99933422, 0.99933511)\n",
      "step: 752, loss: 0.0010729165514931083, accuracy: (0.99933511, 0.999336)\n",
      "step: 753, loss: 0.0010706934845075011, accuracy: (0.999336, 0.9993369)\n",
      "step: 754, loss: 0.0010683083673939109, accuracy: (0.9993369, 0.99933773)\n",
      "step: 755, loss: 0.0010659433901309967, accuracy: (0.99933773, 0.99933863)\n",
      "step: 756, loss: 0.0010637494269758463, accuracy: (0.99933863, 0.99933952)\n",
      "step: 757, loss: 0.0010613607009872794, accuracy: (0.99933952, 0.99934036)\n",
      "step: 758, loss: 0.0010591661557555199, accuracy: (0.99934036, 0.99934125)\n",
      "step: 759, loss: 0.0010569730075076222, accuracy: (0.99934125, 0.99934208)\n",
      "step: 760, loss: 0.0010546280536800623, accuracy: (0.99934208, 0.99934298)\n",
      "step: 761, loss: 0.001052365405485034, accuracy: (0.99934298, 0.99934381)\n",
      "step: 762, loss: 0.0010501476936042309, accuracy: (0.99934381, 0.99934471)\n",
      "step: 763, loss: 0.001047888770699501, accuracy: (0.99934471, 0.99934554)\n",
      "step: 764, loss: 0.0010457333410158753, accuracy: (0.99934554, 0.99934638)\n",
      "step: 765, loss: 0.0010434138821437955, accuracy: (0.99934638, 0.99934727)\n",
      "step: 766, loss: 0.0010412653209641576, accuracy: (0.99934727, 0.9993481)\n",
      "step: 767, loss: 0.0010390740353614092, accuracy: (0.9993481, 0.99934894)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 768, loss: 0.0010368850780650973, accuracy: (0.99934894, 0.99934983)\n",
      "step: 769, loss: 0.0010348174255341291, accuracy: (0.99934983, 0.99935067)\n",
      "step: 770, loss: 0.0010325545445084572, accuracy: (0.99935067, 0.9993515)\n",
      "step: 771, loss: 0.0010303198359906673, accuracy: (0.9993515, 0.99935234)\n",
      "step: 772, loss: 0.001028205151669681, accuracy: (0.99935234, 0.99935317)\n",
      "step: 773, loss: 0.001026033889502287, accuracy: (0.99935317, 0.999354)\n",
      "step: 774, loss: 0.0010239297989755869, accuracy: (0.999354, 0.99935484)\n",
      "step: 775, loss: 0.0010217613307759166, accuracy: (0.99935484, 0.99935567)\n",
      "step: 776, loss: 0.0010197231313213706, accuracy: (0.99935567, 0.99935651)\n",
      "step: 777, loss: 0.0010176155483350158, accuracy: (0.99935651, 0.99935734)\n",
      "step: 778, loss: 0.001015458139590919, accuracy: (0.99935734, 0.99935818)\n",
      "step: 779, loss: 0.0010132892057299614, accuracy: (0.99935818, 0.99935895)\n",
      "step: 780, loss: 0.001011286280117929, accuracy: (0.99935895, 0.99935979)\n",
      "step: 781, loss: 0.001009101397357881, accuracy: (0.99935979, 0.99936062)\n",
      "step: 782, loss: 0.0010070852003991604, accuracy: (0.99936062, 0.99936146)\n",
      "step: 783, loss: 0.001005144091323018, accuracy: (0.99936146, 0.99936223)\n",
      "step: 784, loss: 0.0010029508266597986, accuracy: (0.99936223, 0.99936306)\n",
      "step: 785, loss: 0.0010008380049839616, accuracy: (0.99936306, 0.99936384)\n",
      "step: 786, loss: 0.000998840550892055, accuracy: (0.99936384, 0.99936467)\n",
      "step: 787, loss: 0.0009967952501028776, accuracy: (0.99936467, 0.99936551)\n",
      "step: 788, loss: 0.000994721776805818, accuracy: (0.99936551, 0.99936628)\n",
      "step: 789, loss: 0.0009927016217261553, accuracy: (0.99936628, 0.99936712)\n",
      "step: 790, loss: 0.0009907742496579885, accuracy: (0.99936712, 0.99936789)\n",
      "step: 791, loss: 0.0009886805200949311, accuracy: (0.99936789, 0.99936867)\n",
      "step: 792, loss: 0.0009867474436759949, accuracy: (0.99936867, 0.9993695)\n",
      "step: 793, loss: 0.0009848151821643114, accuracy: (0.9993695, 0.99937028)\n",
      "step: 794, loss: 0.0009827616158872843, accuracy: (0.99937028, 0.99937105)\n",
      "step: 795, loss: 0.000980687327682972, accuracy: (0.99937105, 0.99937189)\n",
      "step: 796, loss: 0.0009788023307919502, accuracy: (0.99937189, 0.99937266)\n",
      "step: 797, loss: 0.0009767586598172784, accuracy: (0.99937266, 0.99937344)\n",
      "step: 798, loss: 0.0009748649899847806, accuracy: (0.99937344, 0.99937421)\n",
      "step: 799, loss: 0.0009730104357004166, accuracy: (0.99937421, 0.99937499)\n",
      "step: 800, loss: 0.0009709250298328698, accuracy: (0.99937499, 0.99937576)\n",
      "step: 801, loss: 0.0009689787402749062, accuracy: (0.99937576, 0.99937654)\n",
      "step: 802, loss: 0.0009670495055615902, accuracy: (0.99937654, 0.99937731)\n",
      "step: 803, loss: 0.0009651185828261077, accuracy: (0.99937731, 0.99937809)\n",
      "step: 804, loss: 0.0009632000583223999, accuracy: (0.99937809, 0.99937886)\n",
      "step: 805, loss: 0.0009613403235562146, accuracy: (0.99937886, 0.99937963)\n",
      "step: 806, loss: 0.0009593531722202897, accuracy: (0.99937963, 0.99938041)\n",
      "step: 807, loss: 0.0009575810399837792, accuracy: (0.99938041, 0.99938118)\n",
      "step: 808, loss: 0.000955668103415519, accuracy: (0.99938118, 0.99938196)\n",
      "step: 809, loss: 0.000953753013163805, accuracy: (0.99938196, 0.99938273)\n",
      "step: 810, loss: 0.0009518143488094211, accuracy: (0.99938273, 0.99938345)\n",
      "step: 811, loss: 0.000949972658418119, accuracy: (0.99938345, 0.99938422)\n",
      "step: 812, loss: 0.000948069617152214, accuracy: (0.99938422, 0.999385)\n",
      "step: 813, loss: 0.0009462855523452163, accuracy: (0.999385, 0.99938577)\n",
      "step: 814, loss: 0.0009443581802770495, accuracy: (0.99938577, 0.99938649)\n",
      "step: 815, loss: 0.0009425178286619484, accuracy: (0.99938649, 0.99938726)\n",
      "step: 816, loss: 0.000940729514695704, accuracy: (0.99938726, 0.99938798)\n",
      "step: 817, loss: 0.0009388441103510559, accuracy: (0.99938798, 0.99938875)\n",
      "step: 818, loss: 0.0009370315819978714, accuracy: (0.99938875, 0.99938947)\n",
      "step: 819, loss: 0.0009351730113849044, accuracy: (0.99938947, 0.99939024)\n",
      "step: 820, loss: 0.0009333677589893341, accuracy: (0.99939024, 0.99939096)\n",
      "step: 821, loss: 0.0009316700743511319, accuracy: (0.99939096, 0.99939173)\n",
      "step: 822, loss: 0.0009298808872699738, accuracy: (0.99939173, 0.99939245)\n",
      "step: 823, loss: 0.0009279795922338963, accuracy: (0.99939245, 0.99939322)\n",
      "step: 824, loss: 0.0009261852246709168, accuracy: (0.99939322, 0.99939394)\n",
      "step: 825, loss: 0.0009244609391316772, accuracy: (0.99939394, 0.99939466)\n",
      "step: 826, loss: 0.000922586303204298, accuracy: (0.99939466, 0.99939543)\n",
      "step: 827, loss: 0.0009209109703078866, accuracy: (0.99939543, 0.99939615)\n",
      "step: 828, loss: 0.0009190767304971814, accuracy: (0.99939615, 0.99939686)\n",
      "step: 829, loss: 0.000917367753572762, accuracy: (0.99939686, 0.99939758)\n",
      "step: 830, loss: 0.0009156912565231323, accuracy: (0.99939758, 0.99939829)\n",
      "step: 831, loss: 0.0009138535824604332, accuracy: (0.99939829, 0.99939907)\n",
      "step: 832, loss: 0.0009120685281231999, accuracy: (0.99939907, 0.99939978)\n",
      "step: 833, loss: 0.0009103139746002853, accuracy: (0.99939978, 0.9994005)\n",
      "step: 834, loss: 0.0009086161153391004, accuracy: (0.9994005, 0.99940121)\n",
      "step: 835, loss: 0.0009068899089470506, accuracy: (0.99940121, 0.99940193)\n",
      "step: 836, loss: 0.0009052235400304198, accuracy: (0.99940193, 0.99940264)\n",
      "step: 837, loss: 0.0009034628164954484, accuracy: (0.99940264, 0.99940336)\n",
      "step: 838, loss: 0.0009017657721415162, accuracy: (0.99940336, 0.99940407)\n",
      "step: 839, loss: 0.0009000831050798297, accuracy: (0.99940407, 0.99940479)\n",
      "step: 840, loss: 0.0008983483421616256, accuracy: (0.99940479, 0.99940544)\n",
      "step: 841, loss: 0.0008966291206888855, accuracy: (0.99940544, 0.99940616)\n",
      "step: 842, loss: 0.0008950365008786321, accuracy: (0.99940616, 0.99940687)\n",
      "step: 843, loss: 0.000893431541044265, accuracy: (0.99940759, 0.99940759)\n",
      "step: 844, loss: 0.0008916390361264348, accuracy: (0.99940759, 0.9994083)\n",
      "step: 845, loss: 0.000889943796209991, accuracy: (0.9994083, 0.99940896)\n",
      "step: 846, loss: 0.0008882844704203308, accuracy: (0.99940896, 0.99940968)\n",
      "step: 847, loss: 0.0008866557036526501, accuracy: (0.99940968, 0.99941039)\n",
      "step: 848, loss: 0.0008849954465404153, accuracy: (0.99941039, 0.99941105)\n",
      "step: 849, loss: 0.0008833541651256382, accuracy: (0.99941105, 0.99941176)\n",
      "step: 850, loss: 0.0008816981571726501, accuracy: (0.99941176, 0.99941248)\n",
      "step: 851, loss: 0.000880068342667073, accuracy: (0.99941248, 0.99941313)\n",
      "step: 852, loss: 0.0008784412639215589, accuracy: (0.99941313, 0.99941385)\n",
      "step: 853, loss: 0.0008768446859903634, accuracy: (0.99941385, 0.9994145)\n",
      "step: 854, loss: 0.0008751899003982544, accuracy: (0.9994145, 0.99941522)\n",
      "step: 855, loss: 0.0008736384916119277, accuracy: (0.99941522, 0.99941587)\n",
      "step: 856, loss: 0.000871950585860759, accuracy: (0.99941587, 0.99941659)\n",
      "step: 857, loss: 0.0008704466745257378, accuracy: (0.99941659, 0.99941725)\n",
      "step: 858, loss: 0.0008688917150720954, accuracy: (0.99941725, 0.9994179)\n",
      "step: 859, loss: 0.0008672006661072373, accuracy: (0.9994179, 0.99941862)\n",
      "step: 860, loss: 0.0008655812707729638, accuracy: (0.99941862, 0.99941927)\n",
      "step: 861, loss: 0.0008640597807243466, accuracy: (0.99941927, 0.99941993)\n",
      "step: 862, loss: 0.0008624127367511392, accuracy: (0.99941993, 0.99942064)\n",
      "step: 863, loss: 0.0008609323995187879, accuracy: (0.99942064, 0.9994213)\n",
      "step: 864, loss: 0.000859276216942817, accuracy: (0.9994213, 0.99942195)\n",
      "step: 865, loss: 0.0008578076958656311, accuracy: (0.99942195, 0.99942261)\n",
      "step: 866, loss: 0.0008562935399822891, accuracy: (0.99942261, 0.99942333)\n",
      "step: 867, loss: 0.0008546425960958004, accuracy: (0.99942333, 0.99942398)\n",
      "step: 868, loss: 0.0008530662162229419, accuracy: (0.99942398, 0.99942464)\n",
      "step: 869, loss: 0.0008515318622812629, accuracy: (0.99942464, 0.99942529)\n",
      "step: 870, loss: 0.0008500530384480953, accuracy: (0.99942529, 0.99942595)\n",
      "step: 871, loss: 0.0008484564605168998, accuracy: (0.99942595, 0.9994266)\n",
      "step: 872, loss: 0.0008469877066090703, accuracy: (0.9994266, 0.99942726)\n",
      "step: 873, loss: 0.000845543690957129, accuracy: (0.99942726, 0.99942791)\n",
      "step: 874, loss: 0.0008439451339654624, accuracy: (0.99942791, 0.99942857)\n",
      "step: 875, loss: 0.0008423612453043461, accuracy: (0.99942857, 0.99942923)\n",
      "step: 876, loss: 0.0008409462752752006, accuracy: (0.99942923, 0.99942988)\n",
      "step: 877, loss: 0.0008393815951421857, accuracy: (0.99942988, 0.99943054)\n",
      "step: 878, loss: 0.0008379234932363033, accuracy: (0.99943054, 0.99943119)\n",
      "step: 879, loss: 0.0008364963578060269, accuracy: (0.99943119, 0.99943179)\n",
      "step: 880, loss: 0.0008349260315299034, accuracy: (0.99943179, 0.99943244)\n",
      "step: 881, loss: 0.0008334393496625125, accuracy: (0.99943244, 0.9994331)\n",
      "step: 882, loss: 0.0008319797925651073, accuracy: (0.9994331, 0.99943376)\n",
      "step: 883, loss: 0.0008304360089823604, accuracy: (0.99943376, 0.99943441)\n",
      "step: 884, loss: 0.0008290464757010341, accuracy: (0.99943441, 0.99943501)\n",
      "step: 885, loss: 0.0008276283042505383, accuracy: (0.99943501, 0.99943566)\n",
      "step: 886, loss: 0.0008261115290224552, accuracy: (0.99943566, 0.99943632)\n",
      "step: 887, loss: 0.0008246179786510766, accuracy: (0.99943632, 0.99943691)\n",
      "step: 888, loss: 0.0008232219843193889, accuracy: (0.99943691, 0.99943757)\n",
      "step: 889, loss: 0.0008217127760872245, accuracy: (0.99943757, 0.99943823)\n",
      "step: 890, loss: 0.0008202944882214069, accuracy: (0.99943823, 0.99943882)\n",
      "step: 891, loss: 0.0008188309147953987, accuracy: (0.99943882, 0.99943948)\n",
      "step: 892, loss: 0.0008174015092663467, accuracy: (0.99943948, 0.99944007)\n",
      "step: 893, loss: 0.0008160116267390549, accuracy: (0.99944007, 0.99944073)\n",
      "step: 894, loss: 0.0008146469481289387, accuracy: (0.99944073, 0.99944133)\n",
      "step: 895, loss: 0.0008131571812555194, accuracy: (0.99944133, 0.99944198)\n",
      "step: 896, loss: 0.0008117204415611923, accuracy: (0.99944198, 0.99944258)\n",
      "step: 897, loss: 0.0008102922001853585, accuracy: (0.99944258, 0.99944323)\n",
      "step: 898, loss: 0.0008089368930086493, accuracy: (0.99944323, 0.99944383)\n",
      "step: 899, loss: 0.0008075073128566146, accuracy: (0.99944383, 0.99944443)\n",
      "step: 900, loss: 0.0008061126573011279, accuracy: (0.99944443, 0.99944508)\n",
      "step: 901, loss: 0.0008048107847571373, accuracy: (0.99944508, 0.99944568)\n",
      "step: 902, loss: 0.0008033459889702499, accuracy: (0.99944568, 0.99944627)\n",
      "step: 903, loss: 0.0008019282249733806, accuracy: (0.99944627, 0.99944693)\n",
      "step: 904, loss: 0.0008006265270523727, accuracy: (0.99944693, 0.99944752)\n",
      "step: 905, loss: 0.0007991631282493472, accuracy: (0.99944752, 0.99944812)\n",
      "step: 906, loss: 0.0007978176581673324, accuracy: (0.99944812, 0.99944872)\n",
      "step: 907, loss: 0.0007964864489622414, accuracy: (0.99944872, 0.99944931)\n",
      "step: 908, loss: 0.0007950607687234879, accuracy: (0.99944931, 0.99944997)\n",
      "step: 909, loss: 0.0007937431219033897, accuracy: (0.99944997, 0.99945056)\n",
      "step: 910, loss: 0.0007923368248157203, accuracy: (0.99945056, 0.99945116)\n",
      "step: 911, loss: 0.0007910812273621559, accuracy: (0.99945116, 0.99945176)\n",
      "step: 912, loss: 0.0007896876777522266, accuracy: (0.99945176, 0.99945235)\n",
      "step: 913, loss: 0.0007882908685132861, accuracy: (0.99945235, 0.99945295)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step: 914, loss: 0.0007870251429267228, accuracy: (0.99945295, 0.99945354)\n",
      "step: 915, loss: 0.0007856501033529639, accuracy: (0.99945354, 0.99945414)\n",
      "step: 916, loss: 0.0007842874038033187, accuracy: (0.99945414, 0.99945474)\n",
      "step: 917, loss: 0.0007830912945792079, accuracy: (0.99945474, 0.99945533)\n",
      "step: 918, loss: 0.0007816998986527324, accuracy: (0.99945533, 0.99945593)\n",
      "step: 919, loss: 0.0007803465123288333, accuracy: (0.99945593, 0.99945652)\n",
      "step: 920, loss: 0.0007790365489199758, accuracy: (0.99945652, 0.99945712)\n",
      "step: 921, loss: 0.0007777181454002857, accuracy: (0.99945712, 0.99945772)\n",
      "step: 922, loss: 0.0007764133624732494, accuracy: (0.99945772, 0.99945831)\n",
      "step: 923, loss: 0.0007751379162073135, accuracy: (0.99945831, 0.99945885)\n",
      "step: 924, loss: 0.0007737842388451099, accuracy: (0.99945885, 0.99945945)\n",
      "step: 925, loss: 0.0007725940668024123, accuracy: (0.99945945, 0.99946004)\n",
      "step: 926, loss: 0.000771285267546773, accuracy: (0.99946004, 0.99946064)\n",
      "step: 927, loss: 0.0007699482375755906, accuracy: (0.99946064, 0.99946123)\n",
      "step: 928, loss: 0.0007686386234126985, accuracy: (0.99946123, 0.99946177)\n",
      "step: 929, loss: 0.0007673882646486163, accuracy: (0.99946177, 0.99946237)\n",
      "step: 930, loss: 0.0007660707924515009, accuracy: (0.99946237, 0.99946296)\n",
      "step: 931, loss: 0.0007648628670722246, accuracy: (0.99946296, 0.9994635)\n",
      "step: 932, loss: 0.000763631600420922, accuracy: (0.9994635, 0.99946409)\n",
      "step: 933, loss: 0.00076228630496189, accuracy: (0.99946409, 0.99946469)\n",
      "step: 934, loss: 0.0007610133616253734, accuracy: (0.99946469, 0.99946523)\n",
      "step: 935, loss: 0.0007597497897222638, accuracy: (0.99946523, 0.99946582)\n",
      "step: 936, loss: 0.0007585023995488882, accuracy: (0.99946582, 0.99946636)\n",
      "step: 937, loss: 0.0007572722970508039, accuracy: (0.99946636, 0.99946696)\n",
      "step: 938, loss: 0.0007560391095466912, accuracy: (0.99946696, 0.99946749)\n",
      "step: 939, loss: 0.0007547502173110843, accuracy: (0.99946749, 0.99946809)\n",
      "step: 940, loss: 0.0007535939803346992, accuracy: (0.99946862, 0.99946862)\n",
      "step: 941, loss: 0.0007523550884798169, accuracy: (0.99946862, 0.99946922)\n",
      "step: 942, loss: 0.0007510918658226728, accuracy: (0.99946922, 0.99946976)\n",
      "step: 943, loss: 0.0007498192135244608, accuracy: (0.99946976, 0.99947035)\n",
      "step: 944, loss: 0.0007486320100724697, accuracy: (0.99947035, 0.99947089)\n",
      "step: 945, loss: 0.0007473798468708992, accuracy: (0.99947089, 0.99947149)\n",
      "step: 946, loss: 0.0007462011417374015, accuracy: (0.99947149, 0.99947202)\n",
      "step: 947, loss: 0.0007450375705957413, accuracy: (0.99947202, 0.99947256)\n",
      "step: 948, loss: 0.0007437490276060998, accuracy: (0.99947256, 0.99947315)\n",
      "step: 949, loss: 0.0007425341755151749, accuracy: (0.99947315, 0.99947369)\n",
      "step: 950, loss: 0.0007413164712488651, accuracy: (0.99947369, 0.99947423)\n",
      "step: 951, loss: 0.0007401464390568435, accuracy: (0.99947423, 0.99947476)\n",
      "step: 952, loss: 0.0007390080136246979, accuracy: (0.99947476, 0.99947536)\n",
      "step: 953, loss: 0.0007377694710157812, accuracy: (0.99947536, 0.9994759)\n",
      "step: 954, loss: 0.0007365407655015588, accuracy: (0.9994759, 0.99947643)\n",
      "step: 955, loss: 0.0007353599066846073, accuracy: (0.99947643, 0.99947697)\n",
      "step: 956, loss: 0.0007341851596720517, accuracy: (0.99947697, 0.99947751)\n",
      "step: 957, loss: 0.0007330080261453986, accuracy: (0.99947751, 0.9994781)\n",
      "step: 958, loss: 0.0007318557472899556, accuracy: (0.9994781, 0.99947864)\n",
      "step: 959, loss: 0.0007306378684006631, accuracy: (0.99947864, 0.99947917)\n",
      "step: 960, loss: 0.0007295161485671997, accuracy: (0.99947917, 0.99947971)\n",
      "step: 961, loss: 0.0007283957675099373, accuracy: (0.99947971, 0.99948025)\n",
      "step: 962, loss: 0.0007271866779774427, accuracy: (0.99948025, 0.99948078)\n",
      "step: 963, loss: 0.0007259766571223736, accuracy: (0.99948078, 0.99948132)\n",
      "step: 964, loss: 0.0007248694309964776, accuracy: (0.99948132, 0.99948186)\n",
      "step: 965, loss: 0.0007236863020807505, accuracy: (0.99948186, 0.99948239)\n",
      "step: 966, loss: 0.0007225375156849623, accuracy: (0.99948239, 0.99948293)\n",
      "step: 967, loss: 0.0007214043289422989, accuracy: (0.99948293, 0.99948347)\n",
      "step: 968, loss: 0.0007202331908047199, accuracy: (0.99948347, 0.999484)\n",
      "step: 969, loss: 0.0007191416225396097, accuracy: (0.999484, 0.99948454)\n",
      "step: 970, loss: 0.0007179658277891576, accuracy: (0.99948454, 0.99948508)\n",
      "step: 971, loss: 0.0007168470183387399, accuracy: (0.99948508, 0.99948561)\n",
      "step: 972, loss: 0.0007157239597290754, accuracy: (0.99948561, 0.99948615)\n",
      "step: 973, loss: 0.000714576686732471, accuracy: (0.99948615, 0.99948663)\n",
      "step: 974, loss: 0.0007134792394936085, accuracy: (0.99948663, 0.99948716)\n",
      "step: 975, loss: 0.0007123047253116965, accuracy: (0.99948716, 0.9994877)\n",
      "step: 976, loss: 0.0007112660678103566, accuracy: (0.9994877, 0.99948823)\n",
      "step: 977, loss: 0.0007101813098415732, accuracy: (0.99948823, 0.99948877)\n",
      "step: 978, loss: 0.0007090016733855009, accuracy: (0.99948877, 0.99948925)\n",
      "step: 979, loss: 0.0007078527705743909, accuracy: (0.99948925, 0.99948978)\n",
      "step: 980, loss: 0.0007067772094160318, accuracy: (0.99948978, 0.99949032)\n",
      "step: 981, loss: 0.0007056781905703247, accuracy: (0.99949032, 0.99949086)\n",
      "step: 982, loss: 0.0007045587408356369, accuracy: (0.99949086, 0.99949133)\n",
      "step: 983, loss: 0.0007034470909275115, accuracy: (0.99949133, 0.99949187)\n",
      "step: 984, loss: 0.0007024341030046344, accuracy: (0.99949187, 0.99949241)\n",
      "step: 985, loss: 0.0007013722788542509, accuracy: (0.99949241, 0.99949288)\n",
      "step: 986, loss: 0.0007002078928053379, accuracy: (0.99949288, 0.99949342)\n",
      "step: 987, loss: 0.0006991244154050946, accuracy: (0.99949342, 0.99949396)\n",
      "step: 988, loss: 0.0006980779580771923, accuracy: (0.99949396, 0.99949443)\n",
      "step: 989, loss: 0.0006969464011490345, accuracy: (0.99949443, 0.99949497)\n",
      "step: 990, loss: 0.0006959486636333168, accuracy: (0.99949497, 0.99949545)\n",
      "step: 991, loss: 0.000694860762450844, accuracy: (0.99949545, 0.99949598)\n",
      "step: 992, loss: 0.0006937716971151531, accuracy: (0.99949598, 0.99949646)\n",
      "step: 993, loss: 0.0006926841451786458, accuracy: (0.99949646, 0.999497)\n",
      "step: 994, loss: 0.0006916363490745425, accuracy: (0.999497, 0.99949747)\n",
      "step: 995, loss: 0.0006905390182510018, accuracy: (0.99949747, 0.99949801)\n",
      "step: 996, loss: 0.0006895270198583603, accuracy: (0.99949801, 0.99949849)\n",
      "step: 997, loss: 0.0006885180482640862, accuracy: (0.99949849, 0.99949902)\n",
      "step: 998, loss: 0.0006874003447592258, accuracy: (0.99949902, 0.9994995)\n",
      "step: 999, loss: 0.0006863378221169114, accuracy: (0.9994995, 0.99949998)\n"
     ]
    }
   ],
   "source": [
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    sess.run(tf.local_variables_initializer())  # accuracy/count is local variable\n",
    "    \n",
    "    for i in range(1000):\n",
    "        _, loss_, acc_ = sess.run([train_op, loss, acc])\n",
    "        print('step: {}, loss: {}, accuracy: {}'.format(i, loss_, acc_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
